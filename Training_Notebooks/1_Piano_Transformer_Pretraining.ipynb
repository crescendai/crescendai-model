{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéπ Piano Perception Transformer - SSAST Pre-training\n",
    "\n",
    "**Phase 1: Self-Supervised Pre-training on MAESTRO Dataset**\n",
    "\n",
    "This notebook implements SSAST (Self-Supervised Audio Spectrogram Transformer) pre-training on the MAESTRO dataset to learn general audio representations that will be fine-tuned for perceptual tasks.\n",
    "\n",
    "**Pipeline Overview:**\n",
    "1. üîß **Setup & Environment** - Dependencies, WandB tracking, JAX configuration\n",
    "2. üíæ **MAESTRO Data Processing** - Streaming download and spectrogram conversion\n",
    "3. üìä **Dataset Creation** - Train/val/test splits with augmentation\n",
    "4. üß† **AST Model Architecture** - 12-layer production transformer\n",
    "5. üöÄ **SSAST Pre-training** - Self-supervised learning execution\n",
    "\n",
    "**Output:** Pre-trained model checkpoint ready for fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîß Cell 1: Enhanced Setup with WandB Integration\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Setting up Piano Perception Transformer - Production Version...\")\n",
    "\n",
    "# Clone repo (skip if already exists)\n",
    "import os\n",
    "if not os.path.exists('piano-perception-transformer'):\n",
    "    !git clone https://github.com/Jai-Dhiman/piano-perception-transformer.git\n",
    "else:\n",
    "    print(\"Repository already exists, skipping clone...\")\n",
    "\n",
    "%cd piano-perception-transformer\n",
    "\n",
    "# Install uv\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "# Install enhanced dependencies including ML research tools\n",
    "print(\"üì¶ Installing enhanced dependencies with uv...\")\n",
    "!export PATH=\"/usr/local/bin:$PATH\" && uv pip install --system jax[tpu] flax optax librosa pandas wandb requests zipfile36 scikit-learn scipy seaborn matplotlib pretty_midi soundfile\n",
    "\n",
    "# Initialize WandB for experiment tracking\n",
    "import wandb\n",
    "import jax\n",
    "from datetime import datetime\n",
    "\n",
    "# WandB Setup\n",
    "try:\n",
    "    wandb.login()  # This will prompt for API key in Colab\n",
    "    \n",
    "    run = wandb.init(\n",
    "        project=\"piano-perception-transformer-pretraining\",\n",
    "        name=f\"ssast-pretraining-{datetime.now().strftime('%Y%m%d-%H%M')}\",\n",
    "        config={\n",
    "            \"phase\": \"ssast_pretraining\",\n",
    "            \"architecture\": \"Production AST-SSAST\",\n",
    "            \"model_layers\": 12,\n",
    "            \"embed_dim\": 768,\n",
    "            \"num_heads\": 12,\n",
    "            \"patch_size\": 16,\n",
    "            \"learning_rate\": 5e-5,\n",
    "            \"batch_size\": 32,\n",
    "            \"dropout\": 0.1,\n",
    "            \"stochastic_depth\": 0.1,\n",
    "            \"dataset\": \"MAESTRO-v3\",\n",
    "            \"experiment_type\": \"self_supervised_pretraining\"\n",
    "        },\n",
    "        tags=[\"pretraining\", \"ssast\", \"maestro\", \"self-supervised\"]\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ WandB initialized successfully!\")\n",
    "    print(f\"   ‚Ä¢ Project: piano-perception-transformer-pretraining\")\n",
    "    print(f\"   ‚Ä¢ Run name: {run.name}\")\n",
    "    print(f\"   ‚Ä¢ Tracking: https://wandb.ai/{run.entity}/{run.project}/runs/{run.id}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è WandB initialization failed: {e}\")\n",
    "    print(\"   ‚Ä¢ Continuing without experiment tracking\")\n",
    "    print(\"   ‚Ä¢ Set up WandB API key: https://wandb.ai/settings\")\n",
    "\n",
    "# Verify JAX setup\n",
    "print(f\"\\nüß† JAX Configuration:\")\n",
    "print(f\"   ‚Ä¢ Backend: {jax.default_backend()}\")\n",
    "print(f\"   ‚Ä¢ Devices: {jax.device_count()}\")\n",
    "print(f\"   ‚Ä¢ Device type: {jax.devices()[0].device_kind}\")\n",
    "\n",
    "print(\"\\n‚úÖ Enhanced setup completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üíæ Cell 2: Mount Google Drive & Setup Storage\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "print(\"üîó Mounting Google Drive for persistent storage...\")\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directory structure\n",
    "base_dir = '/content/drive/MyDrive/piano_transformer'\n",
    "directories = [\n",
    "    f'{base_dir}/processed_spectrograms',\n",
    "    f'{base_dir}/checkpoints/ssast_pretraining',\n",
    "    f'{base_dir}/logs',\n",
    "    f'{base_dir}/temp'\n",
    "]\n",
    "\n",
    "print(\"üìÅ Setting up directory structure...\")\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"‚úÖ Created: {directory}\")\n",
    "\n",
    "print(\"\\n‚úÖ Google Drive mounted and directories ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üåä Cell 3: Streaming MAESTRO Processing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from io import BytesIO\n",
    "sys.path.append('./src')\n",
    "\n",
    "print(\"üåä Starting streaming MAESTRO processing...\")\n",
    "\n",
    "def download_and_process_maestro_streaming(max_files=None):\n",
    "    \"\"\"Download MAESTRO ZIP as stream, extract and process audio‚Üíspectrograms, save to Drive\"\"\"\n",
    "    \n",
    "    # Download metadata first to get real file paths\n",
    "    print(\"üìã Downloading MAESTRO metadata...\")\n",
    "    metadata_url = \"https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0.json\"\n",
    "    \n",
    "    try:\n",
    "        metadata_response = requests.get(metadata_url, timeout=30)\n",
    "        metadata_response.raise_for_status()\n",
    "        maestro_metadata = metadata_response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Failed to download metadata: {e}\")\n",
    "        raise Exception(f\"Cannot download MAESTRO metadata: {e}\")\n",
    "    \n",
    "    print(f\"üìä Found metadata for MAESTRO dataset\")\n",
    "    \n",
    "    # Save metadata to Drive\n",
    "    try:\n",
    "        with open('/content/drive/MyDrive/piano_transformer/maestro_metadata.json', 'w') as f:\n",
    "            json.dump(maestro_metadata, f)\n",
    "        print(\"‚úÖ Metadata saved to Drive\")\n",
    "    except IOError as e:\n",
    "        print(f\"‚ùå Failed to save metadata: {e}\")\n",
    "        raise Exception(f\"Cannot save metadata to Drive: {e}\")\n",
    "    \n",
    "    # Process MAESTRO metadata structure\n",
    "    if not isinstance(maestro_metadata, dict):\n",
    "        raise Exception(f\"Expected dict metadata, got {type(maestro_metadata)}\")\n",
    "    \n",
    "    # Check for required fields\n",
    "    required_fields = ['audio_filename', 'canonical_composer', 'canonical_title']\n",
    "    for field in required_fields:\n",
    "        if field not in maestro_metadata:\n",
    "            raise Exception(f\"Required field '{field}' not found in metadata. Available fields: {list(maestro_metadata.keys())}\")\n",
    "    \n",
    "    # Get the audio filenames from the pandas-style structure\n",
    "    audio_filenames = maestro_metadata['audio_filename']\n",
    "    if not isinstance(audio_filenames, dict):\n",
    "        raise Exception(f\"Expected dict for audio_filename field, got {type(audio_filenames)}\")\n",
    "    \n",
    "    total_files = len(audio_filenames)\n",
    "    print(f\"üìù Found {total_files} audio files in metadata\")\n",
    "    \n",
    "    # Get list of audio files to process\n",
    "    target_files = set()\n",
    "    files_to_process = list(audio_filenames.items())\n",
    "    if max_files:\n",
    "        files_to_process = files_to_process[:max_files]\n",
    "        print(f\"üéØ Processing first {max_files} files for demo/testing\")\n",
    "    else:\n",
    "        print(f\"üéØ Processing all {total_files} files\")\n",
    "    \n",
    "    for idx, filename in files_to_process:\n",
    "        if filename and isinstance(filename, str) and filename.endswith('.wav'):\n",
    "            target_files.add(filename)\n",
    "    \n",
    "    if not target_files:\n",
    "        raise Exception(\"No valid .wav files found in metadata\")\n",
    "    \n",
    "    print(f\"üéµ Target: {len(target_files)} audio files from ZIP\")\n",
    "    \n",
    "    # Download and stream process the MAESTRO ZIP\n",
    "    zip_url = \"https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0.zip\"\n",
    "    print(f\"üì¶ Downloading MAESTRO ZIP stream from: {zip_url}\")\n",
    "    \n",
    "    processed_count = 0\n",
    "    \n",
    "    try:\n",
    "        # Stream download the ZIP file\n",
    "        with requests.get(zip_url, stream=True, timeout=300) as zip_response:\n",
    "            zip_response.raise_for_status()\n",
    "            \n",
    "            print(\"‚úÖ ZIP stream connected, processing...\")\n",
    "            \n",
    "            # Create a temporary file to hold the ZIP stream\n",
    "            with tempfile.NamedTemporaryFile(suffix='.zip') as temp_zip:\n",
    "                # Download ZIP in chunks to avoid memory issues\n",
    "                total_size = int(zip_response.headers.get('content-length', 0))\n",
    "                downloaded = 0\n",
    "                \n",
    "                print(f\"üìä ZIP size: {total_size / (1024**3):.1f}GB\")\n",
    "                \n",
    "                for chunk in zip_response.iter_content(chunk_size=8192 * 1024):  # 8MB chunks\n",
    "                    if chunk:\n",
    "                        temp_zip.write(chunk)\n",
    "                        downloaded += len(chunk)\n",
    "                        \n",
    "                        # Show progress every 1GB\n",
    "                        if downloaded % (1024**3) < (8192 * 1024):\n",
    "                            progress = (downloaded / total_size) * 100 if total_size > 0 else 0\n",
    "                            print(f\"üì• Downloaded: {downloaded / (1024**3):.1f}GB ({progress:.1f}%)\")\n",
    "                \n",
    "                print(\"‚úÖ ZIP download completed, extracting audio files...\")\n",
    "                temp_zip.seek(0)  # Reset file pointer\n",
    "                \n",
    "                # Process ZIP contents\n",
    "                with zipfile.ZipFile(temp_zip, 'r') as zip_file:\n",
    "                    # Get list of files in ZIP\n",
    "                    zip_files = zip_file.namelist()\n",
    "                    audio_files_in_zip = [f for f in zip_files if f.endswith('.wav')]\n",
    "                    \n",
    "                    print(f\"üìÇ Found {len(audio_files_in_zip)} audio files in ZIP\")\n",
    "                    \n",
    "                    # Process target files found in ZIP\n",
    "                    for zip_audio_path in audio_files_in_zip:\n",
    "                        # Check if this file is in our target list\n",
    "                        audio_filename = Path(zip_audio_path).name\n",
    "                        if not any(audio_filename in target_file for target_file in target_files):\n",
    "                            continue\n",
    "                            \n",
    "                        try:\n",
    "                            print(f\"üéõÔ∏è Processing: {audio_filename}...\")\n",
    "                            \n",
    "                            # Extract audio file to memory\n",
    "                            with zip_file.open(zip_audio_path) as audio_file:\n",
    "                                audio_data = audio_file.read()\n",
    "                            \n",
    "                            # Save to temp file for librosa\n",
    "                            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_audio:\n",
    "                                temp_audio.write(audio_data)\n",
    "                                temp_audio_path = temp_audio.name\n",
    "                            \n",
    "                            try:\n",
    "                                # Load audio (limit duration to save memory)\n",
    "                                y, sr = librosa.load(temp_audio_path, sr=22050, duration=60.0)  # 60 seconds\n",
    "                                \n",
    "                                # Generate mel-spectrogram\n",
    "                                mel_spec = librosa.feature.melspectrogram(\n",
    "                                    y=y, sr=sr, n_fft=2048, hop_length=512, n_mels=128\n",
    "                                )\n",
    "                                mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "                                \n",
    "                                # Save spectrogram to Drive\n",
    "                                spec_filename = Path(audio_filename).stem + '_mel.npy'\n",
    "                                spec_path = f'/content/drive/MyDrive/piano_transformer/processed_spectrograms/{spec_filename}'\n",
    "                                \n",
    "                                np.save(spec_path, mel_spec_db)\n",
    "                                print(f\"‚úÖ Saved: {spec_filename} (shape: {mel_spec_db.shape})\")\n",
    "                                processed_count += 1\n",
    "                                \n",
    "                                # Check if we've reached our target (if max_files is set)\n",
    "                                if max_files and processed_count >= max_files:\n",
    "                                    print(f\"üéØ Reached target limit of {processed_count} files\")\n",
    "                                    break\n",
    "                                    \n",
    "                            except Exception as audio_error:\n",
    "                                print(f\"‚ùå Audio processing error: {audio_error}\")\n",
    "                                continue\n",
    "                            finally:\n",
    "                                # Cleanup temp audio file\n",
    "                                if os.path.exists(temp_audio_path):\n",
    "                                    os.remove(temp_audio_path)\n",
    "                                    \n",
    "                        except Exception as extract_error:\n",
    "                            print(f\"‚ùå Extraction error for {zip_audio_path}: {extract_error}\")\n",
    "                            continue\n",
    "                        \n",
    "                        # Storage check periodically\n",
    "                        if processed_count % 10 == 0:\n",
    "                            try:\n",
    "                                storage_info = os.statvfs('/content')\n",
    "                                free_gb = (storage_info.f_bavail * storage_info.f_frsize) / (1024**3)\n",
    "                                print(f\"üíæ Storage: {free_gb:.1f}GB free, {processed_count} files processed\")\n",
    "                            except OSError:\n",
    "                                pass\n",
    "                        \n",
    "                        # Break if we've reached our target\n",
    "                        if max_files and processed_count >= max_files:\n",
    "                            break\n",
    "    \n",
    "    except requests.exceptions.RequestException as download_error:\n",
    "        raise Exception(f\"Failed to download MAESTRO ZIP: {download_error}\")\n",
    "    except zipfile.BadZipFile as zip_error:\n",
    "        raise Exception(f\"Invalid ZIP file: {zip_error}\")\n",
    "    except Exception as general_error:\n",
    "        raise Exception(f\"Processing error: {general_error}\")\n",
    "    \n",
    "    print(f\"\\nüéâ Streaming processing completed!\")\n",
    "    print(f\"‚úÖ Successfully processed: {processed_count} files\")\n",
    "    print(f\"üíæ Spectrograms saved to: /content/drive/MyDrive/piano_transformer/processed_spectrograms/\")\n",
    "    \n",
    "    if processed_count == 0:\n",
    "        raise Exception(\"No files were successfully processed\")\n",
    "    \n",
    "    return processed_count\n",
    "\n",
    "\n",
    "# Run streaming processing with proper error handling\n",
    "try:\n",
    "    # Set max_files=None to process all files, or set a number for testing\n",
    "    # For testing: max_files=50\n",
    "    # For full dataset: max_files=None\n",
    "    num_processed = download_and_process_maestro_streaming(max_files=None)\n",
    "    print(f\"\\n‚úÖ SUCCESS: {num_processed} MAESTRO files processed!\")\n",
    "    print(\"üéØ Ready to proceed with pre-training on processed spectrograms\")\n",
    "        \n",
    "except Exception as main_error:\n",
    "    print(f\"‚ùå Processing failed: {main_error}\")\n",
    "    raise Exception(f\"MAESTRO processing failed: {main_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Cell 4: Enhanced Dataset Setup with Train/Val/Test Splits\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from pathlib import Path\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"üìä Enhanced Dataset Setup with Proper Splits & Augmentation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class EnhancedMAESTRODataset:\n",
    "    \"\"\"Enhanced MAESTRO dataset with proper train/val/test splits and augmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, spec_dir, split='train', train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, \n",
    "                 augmentation=True, target_shape=(128, 128), random_seed=42):\n",
    "        \"\"\"\n",
    "        Initialize dataset with proper splits\n",
    "        \n",
    "        Args:\n",
    "            spec_dir: Directory containing processed spectrograms\n",
    "            split: 'train', 'val', or 'test'\n",
    "            train_ratio: Proportion for training\n",
    "            val_ratio: Proportion for validation  \n",
    "            test_ratio: Proportion for testing\n",
    "            augmentation: Whether to apply data augmentation (train only)\n",
    "            target_shape: Target spectrogram shape (time, freq)\n",
    "            random_seed: Random seed for reproducible splits\n",
    "        \"\"\"\n",
    "        self.spec_dir = spec_dir\n",
    "        self.split = split\n",
    "        self.augmentation = augmentation and (split == 'train')\n",
    "        self.target_shape = target_shape\n",
    "        self.random_seed = random_seed\n",
    "        \n",
    "        # Validate split ratios\n",
    "        assert abs((train_ratio + val_ratio + test_ratio) - 1.0) < 1e-6, \"Split ratios must sum to 1.0\"\n",
    "        \n",
    "        # Get all spectrogram files\n",
    "        all_files = [f for f in os.listdir(spec_dir) if f.endswith('_mel.npy')]\n",
    "        \n",
    "        if len(all_files) == 0:\n",
    "            raise FileNotFoundError(f\"No spectrogram files found in {spec_dir}\")\n",
    "        \n",
    "        print(f\"üìÅ Found {len(all_files)} total spectrogram files\")\n",
    "        \n",
    "        # Create reproducible train/val/test splits\n",
    "        np.random.seed(random_seed)\n",
    "        random.seed(random_seed)\n",
    "        \n",
    "        # First split: train vs (val + test)\n",
    "        train_files, temp_files = train_test_split(\n",
    "            all_files, \n",
    "            test_size=(val_ratio + test_ratio), \n",
    "            random_state=random_seed\n",
    "        )\n",
    "        \n",
    "        # Second split: val vs test\n",
    "        val_size = val_ratio / (val_ratio + test_ratio)\n",
    "        val_files, test_files = train_test_split(\n",
    "            temp_files, \n",
    "            test_size=(1 - val_size), \n",
    "            random_state=random_seed\n",
    "        )\n",
    "        \n",
    "        # Assign files based on split\n",
    "        if split == 'train':\n",
    "            self.files = train_files\n",
    "        elif split == 'val':\n",
    "            self.files = val_files\n",
    "        elif split == 'test':\n",
    "            self.files = test_files\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid split: {split}. Must be 'train', 'val', or 'test'\")\n",
    "        \n",
    "        self.num_files = len(self.files)\n",
    "        \n",
    "        print(f\"üìä Split Statistics:\")\n",
    "        print(f\"   ‚Ä¢ Train: {len(train_files)} files ({len(train_files)/len(all_files)*100:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ Val:   {len(val_files)} files ({len(val_files)/len(all_files)*100:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ Test:  {len(test_files)} files ({len(test_files)/len(all_files)*100:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ Using: {self.num_files} files for '{split}' split\")\n",
    "        \n",
    "        if self.augmentation:\n",
    "            print(f\"‚ú® Data augmentation enabled for training\")\n",
    "        else:\n",
    "            print(f\"üîí No augmentation (validation/test mode)\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_files\n",
    "    \n",
    "    def load_spectrogram(self, filename):\n",
    "        \"\"\"Load and normalize a single spectrogram\"\"\"\n",
    "        filepath = os.path.join(self.spec_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            spec = np.load(filepath)\n",
    "            \n",
    "            # Transpose to [time, freq] if needed\n",
    "            if spec.shape[0] > spec.shape[1]:  # Likely [freq, time], need [time, freq]\n",
    "                spec = spec.T\n",
    "            \n",
    "            # Resize to target shape\n",
    "            target_time, target_freq = self.target_shape\n",
    "            current_time, current_freq = spec.shape\n",
    "            \n",
    "            # Handle time dimension\n",
    "            if current_time >= target_time:\n",
    "                # Truncate\n",
    "                spec = spec[:target_time, :]\n",
    "            else:\n",
    "                # Pad with silence (-80 dB)\n",
    "                pad_width = target_time - current_time\n",
    "                spec = np.pad(spec, ((0, pad_width), (0, 0)), mode='constant', constant_values=-80.0)\n",
    "            \n",
    "            # Handle frequency dimension \n",
    "            if current_freq >= target_freq:\n",
    "                # Truncate \n",
    "                spec = spec[:, :target_freq]\n",
    "            else:\n",
    "                # Pad with silence\n",
    "                pad_width = target_freq - current_freq\n",
    "                spec = np.pad(spec, ((0, 0), (0, pad_width)), mode='constant', constant_values=-80.0)\n",
    "            \n",
    "            # Final shape verification\n",
    "            assert spec.shape == self.target_shape, f\"Shape mismatch: got {spec.shape}, expected {self.target_shape}\"\n",
    "            \n",
    "            return spec.astype(np.float32)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading {filename}: {e}\")\n",
    "            # Return silence spectrogram as fallback\n",
    "            return np.full(self.target_shape, -80.0, dtype=np.float32)\n",
    "    \n",
    "    def augment_spectrogram(self, spec):\n",
    "        \"\"\"Apply data augmentation to spectrogram\"\"\"\n",
    "        if not self.augmentation:\n",
    "            return spec\n",
    "        \n",
    "        # Time masking (SpecAugment style)\n",
    "        if np.random.random() < 0.5:\n",
    "            time_mask_length = np.random.randint(1, min(20, spec.shape[0] // 4))\n",
    "            time_mask_start = np.random.randint(0, spec.shape[0] - time_mask_length)\n",
    "            spec = spec.copy()\n",
    "            spec[time_mask_start:time_mask_start + time_mask_length, :] = -80.0\n",
    "        \n",
    "        # Frequency masking\n",
    "        if np.random.random() < 0.5:\n",
    "            freq_mask_length = np.random.randint(1, min(15, spec.shape[1] // 4))\n",
    "            freq_mask_start = np.random.randint(0, spec.shape[1] - freq_mask_length)\n",
    "            spec = spec.copy()\n",
    "            spec[:, freq_mask_start:freq_mask_start + freq_mask_length] = -80.0\n",
    "        \n",
    "        # Gaussian noise\n",
    "        if np.random.random() < 0.3:\n",
    "            noise_factor = np.random.uniform(0.01, 0.05)\n",
    "            noise = np.random.normal(0, noise_factor, spec.shape)\n",
    "            spec = spec + noise\n",
    "        \n",
    "        # Volume scaling\n",
    "        if np.random.random() < 0.4:\n",
    "            scale_factor = np.random.uniform(0.8, 1.2)\n",
    "            spec = spec * scale_factor\n",
    "        \n",
    "        return spec\n",
    "    \n",
    "    def get_batch(self, batch_size, shuffle=None):\n",
    "        \"\"\"Get a batch of spectrograms\"\"\"\n",
    "        # Default shuffle behavior: True for train, False for val/test\n",
    "        if shuffle is None:\n",
    "            shuffle = (self.split == 'train')\n",
    "        \n",
    "        if shuffle:\n",
    "            # Random sampling with replacement for training\n",
    "            indices = np.random.choice(self.num_files, size=batch_size, replace=True)\n",
    "        else:\n",
    "            # Sequential sampling for consistent validation/test results\n",
    "            start_idx = np.random.randint(0, max(1, self.num_files - batch_size + 1))\n",
    "            indices = np.arange(start_idx, start_idx + batch_size) % self.num_files\n",
    "        \n",
    "        batch_specs = []\n",
    "        \n",
    "        for idx in indices:\n",
    "            filename = self.files[idx]\n",
    "            spec = self.load_spectrogram(filename)\n",
    "            spec = self.augment_spectrogram(spec)  # Will be no-op if augmentation disabled\n",
    "            batch_specs.append(spec)\n",
    "        \n",
    "        return np.array(batch_specs)\n",
    "\n",
    "# Initialize enhanced datasets with proper splits\n",
    "spec_dir = '/content/drive/MyDrive/piano_transformer/processed_spectrograms'\n",
    "\n",
    "print(f\"\\nüîß Creating enhanced MAESTRO datasets...\")\n",
    "\n",
    "try:\n",
    "    # Create datasets for each split\n",
    "    train_dataset = EnhancedMAESTRODataset(\n",
    "        spec_dir=spec_dir, \n",
    "        split='train',\n",
    "        train_ratio=0.7, \n",
    "        val_ratio=0.15, \n",
    "        test_ratio=0.15,\n",
    "        augmentation=True,  # Enable augmentation for training\n",
    "        target_shape=(128, 128),\n",
    "        random_seed=42\n",
    "    )\n",
    "    \n",
    "    val_dataset = EnhancedMAESTRODataset(\n",
    "        spec_dir=spec_dir,\n",
    "        split='val', \n",
    "        train_ratio=0.7, \n",
    "        val_ratio=0.15, \n",
    "        test_ratio=0.15,\n",
    "        augmentation=False,  # No augmentation for validation\n",
    "        target_shape=(128, 128),\n",
    "        random_seed=42\n",
    "    )\n",
    "    \n",
    "    test_dataset = EnhancedMAESTRODataset(\n",
    "        spec_dir=spec_dir,\n",
    "        split='test',\n",
    "        train_ratio=0.7, \n",
    "        val_ratio=0.15, \n",
    "        test_ratio=0.15,\n",
    "        augmentation=False,  # No augmentation for testing\n",
    "        target_shape=(128, 128),\n",
    "        random_seed=42\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Enhanced datasets created successfully!\")\n",
    "    print(f\"   ‚Ä¢ Training dataset: {len(train_dataset)} files (with augmentation)\")\n",
    "    print(f\"   ‚Ä¢ Validation dataset: {len(val_dataset)} files (no augmentation)\")\n",
    "    print(f\"   ‚Ä¢ Test dataset: {len(test_dataset)} files (no augmentation)\")\n",
    "    \n",
    "    # Test batch loading with augmentation\n",
    "    print(f\"\\nüß™ Testing enhanced data pipeline...\")\n",
    "    train_batch = train_dataset.get_batch(4)\n",
    "    val_batch = val_dataset.get_batch(4)\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Train batch shape: {train_batch.shape}\")\n",
    "    print(f\"   ‚Ä¢ Val batch shape: {val_batch.shape}\")\n",
    "    print(f\"   ‚Ä¢ Train batch stats: min={train_batch.min():.2f}, max={train_batch.max():.2f}, mean={train_batch.mean():.2f}\")\n",
    "    print(f\"   ‚Ä¢ Val batch stats: min={val_batch.min():.2f}, max={val_batch.max():.2f}, mean={val_batch.mean():.2f}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Ready for SSAST pre-training!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Dataset creation failed: {e}\")\n",
    "    raise Exception(f\"Enhanced dataset setup failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üß† Cell 5: Production AST Model Architecture\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "from datetime import datetime\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import time\n",
    "\n",
    "sys.path.append('/content/piano-perception-transformer/src')\n",
    "\n",
    "print(\"üß† Production AST Model + Enhanced Training Pipeline\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class ProductionASTForSSAST(nn.Module):\n",
    "    \"\"\"Production AST implementation for SSAST pre-training\n",
    "    \n",
    "    Based on Gong et al. 2021 - Audio Spectrogram Transformer\n",
    "    - 12 transformer layers (full production scale)\n",
    "    - 768 embedding dimensions\n",
    "    - 12 attention heads\n",
    "    - Stochastic depth regularization\n",
    "    - Self-supervised pre-training objective\n",
    "    \"\"\"\n",
    "    \n",
    "    patch_size: int = 16\n",
    "    embed_dim: int = 768\n",
    "    num_layers: int = 12\n",
    "    num_heads: int = 12\n",
    "    mlp_ratio: float = 4.0\n",
    "    dropout_rate: float = 0.1\n",
    "    attention_dropout: float = 0.1\n",
    "    stochastic_depth_rate: float = 0.1\n",
    "    \n",
    "    def setup(self):\n",
    "        # Pre-compute stochastic depth drop rates (linearly increasing)\n",
    "        self.drop_rates = [\n",
    "            self.stochastic_depth_rate * i / (self.num_layers - 1) \n",
    "            for i in range(self.num_layers)\n",
    "        ]\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x, training: bool = True):\n",
    "        \"\"\"\n",
    "        Full production AST forward pass for pre-training\n",
    "        Args:\n",
    "            x: Mel-spectrogram [batch, time, freq] -> (batch, 128, 128)\n",
    "        Returns:\n",
    "            features: [batch, num_patches, embed_dim] - representations for self-supervised learning\n",
    "        \"\"\"\n",
    "        batch_size, time_frames, freq_bins = x.shape\n",
    "        \n",
    "        # === PATCH EMBEDDING ===\n",
    "        patch_size = self.patch_size\n",
    "        \n",
    "        # Ensure input can be divided into patches  \n",
    "        time_pad = (patch_size - time_frames % patch_size) % patch_size\n",
    "        freq_pad = (patch_size - freq_bins % patch_size) % patch_size\n",
    "        \n",
    "        if time_pad > 0 or freq_pad > 0:\n",
    "            x = jnp.pad(x, ((0, 0), (0, time_pad), (0, freq_pad)), mode='constant', constant_values=-80.0)\n",
    "        \n",
    "        time_patches = x.shape[1] // patch_size\n",
    "        freq_patches = x.shape[2] // patch_size\n",
    "        num_patches = time_patches * freq_patches\n",
    "        \n",
    "        # Reshape to patches: [batch, num_patches, patch_dim]\n",
    "        x = x.reshape(batch_size, time_patches, patch_size, freq_patches, patch_size)\n",
    "        x = x.transpose(0, 1, 3, 2, 4)  # [batch, time_patches, freq_patches, patch_size, patch_size]\n",
    "        x = x.reshape(batch_size, num_patches, patch_size * patch_size)\n",
    "        \n",
    "        # Linear patch embedding\n",
    "        x = nn.Dense(\n",
    "            self.embed_dim, \n",
    "            kernel_init=nn.initializers.truncated_normal(stddev=0.02),\n",
    "            bias_init=nn.initializers.zeros,\n",
    "            name='patch_embedding'\n",
    "        )(x)\n",
    "        \n",
    "        # === 2D POSITIONAL ENCODING ===\n",
    "        pos_embedding = self.param(\n",
    "            'pos_embedding',\n",
    "            nn.initializers.truncated_normal(stddev=0.02),\n",
    "            (1, num_patches, self.embed_dim)\n",
    "        )\n",
    "        x = x + pos_embedding\n",
    "        \n",
    "        # Embedding dropout\n",
    "        x = nn.Dropout(self.dropout_rate, deterministic=not training)(x)\n",
    "        \n",
    "        # === 12-LAYER TRANSFORMER ENCODER ===\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            # Stochastic depth probability for this layer\n",
    "            drop_rate = self.drop_rates[layer_idx]\n",
    "            \n",
    "            # Multi-Head Self-Attention Block\n",
    "            residual = x\n",
    "            x = nn.LayerNorm(epsilon=1e-6, name=f'norm1_layer{layer_idx}')(x)\n",
    "            \n",
    "            attention = nn.MultiHeadDotProductAttention(\n",
    "                num_heads=self.num_heads,\n",
    "                dropout_rate=self.attention_dropout,\n",
    "                kernel_init=nn.initializers.truncated_normal(stddev=0.02),\n",
    "                bias_init=nn.initializers.zeros,\n",
    "                name=f'attention_layer{layer_idx}'\n",
    "            )(x, x, deterministic=not training)\n",
    "            \n",
    "            # Stochastic depth for attention (training only)\n",
    "            if training and drop_rate > 0:\n",
    "                random_tensor = jax.random.uniform(\n",
    "                    self.make_rng('stochastic_depth'), (batch_size, 1, 1)\n",
    "                )\n",
    "                keep_prob = 1.0 - drop_rate\n",
    "                binary_tensor = (random_tensor < keep_prob).astype(x.dtype)\n",
    "                attention = attention * binary_tensor / keep_prob\n",
    "            \n",
    "            x = residual + nn.Dropout(self.dropout_rate, deterministic=not training)(attention)\n",
    "            \n",
    "            # Feed-Forward Network Block\n",
    "            residual = x\n",
    "            x = nn.LayerNorm(epsilon=1e-6, name=f'norm2_layer{layer_idx}')(x)\n",
    "            \n",
    "            # MLP with 4x expansion\n",
    "            mlp_hidden = int(self.embed_dim * self.mlp_ratio)\n",
    "            \n",
    "            mlp = nn.Dense(\n",
    "                mlp_hidden, \n",
    "                kernel_init=nn.initializers.truncated_normal(stddev=0.02),\n",
    "                bias_init=nn.initializers.zeros,\n",
    "                name=f'mlp_dense1_layer{layer_idx}'\n",
    "            )(x)\n",
    "            mlp = nn.gelu(mlp)\n",
    "            mlp = nn.Dropout(self.dropout_rate, deterministic=not training)(mlp)\n",
    "            \n",
    "            mlp = nn.Dense(\n",
    "                self.embed_dim,\n",
    "                kernel_init=nn.initializers.truncated_normal(stddev=0.02),\n",
    "                bias_init=nn.initializers.zeros,\n",
    "                name=f'mlp_dense2_layer{layer_idx}'\n",
    "            )(mlp)\n",
    "            \n",
    "            # Stochastic depth for MLP\n",
    "            if training and drop_rate > 0:\n",
    "                random_tensor = jax.random.uniform(\n",
    "                    self.make_rng('stochastic_depth'), (batch_size, 1, 1)\n",
    "                )\n",
    "                keep_prob = 1.0 - drop_rate\n",
    "                binary_tensor = (random_tensor < keep_prob).astype(x.dtype)\n",
    "                mlp = mlp * binary_tensor / keep_prob\n",
    "            \n",
    "            x = residual + nn.Dropout(self.dropout_rate, deterministic=not training)(mlp)\n",
    "        \n",
    "        # === FINAL NORMALIZATION ===\n",
    "        x = nn.LayerNorm(epsilon=1e-6, name='final_norm')(x)\n",
    "        \n",
    "        # For SSAST pre-training, we return the raw features\n",
    "        # These will be used for self-supervised objectives\n",
    "        return x  # Shape: [batch, num_patches, embed_dim]\n",
    "\n",
    "def create_advanced_optimizer(total_steps, learning_rate=5e-5, weight_decay=0.01, warmup_steps=1000):\n",
    "    \"\"\"Create advanced optimizer with cosine decay and warmup\"\"\"\n",
    "    \n",
    "    # Cosine decay schedule with warmup\n",
    "    warmup_schedule = optax.linear_schedule(\n",
    "        init_value=1e-8,\n",
    "        end_value=learning_rate,\n",
    "        transition_steps=warmup_steps\n",
    "    )\n",
    "    \n",
    "    cosine_schedule = optax.cosine_decay_schedule(\n",
    "        init_value=learning_rate,\n",
    "        decay_steps=total_steps - warmup_steps,\n",
    "        alpha=0.01  # Final LR = 1% of initial LR\n",
    "    )\n",
    "    \n",
    "    lr_schedule = optax.join_schedules(\n",
    "        schedules=[warmup_schedule, cosine_schedule],\n",
    "        boundaries=[warmup_steps]\n",
    "    )\n",
    "    \n",
    "    # AdamW optimizer with gradient clipping\n",
    "    optimizer = optax.chain(\n",
    "        optax.clip_by_global_norm(1.0),  # Gradient clipping\n",
    "        optax.adamw(\n",
    "            learning_rate=lr_schedule,\n",
    "            weight_decay=weight_decay,\n",
    "            b1=0.9,\n",
    "            b2=0.999,\n",
    "            eps=1e-8\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return optimizer\n",
    "\n",
    "def get_learning_rate_from_optimizer(opt_state, step):\n",
    "    \"\"\"Extract current learning rate from optimizer state\"\"\"\n",
    "    try:\n",
    "        # Try to get learning rate from the schedule directly\n",
    "        # This works for most modern optax optimizers with schedules\n",
    "        if hasattr(opt_state, 'hyperparams') and 'learning_rate' in opt_state.hyperparams:\n",
    "            return opt_state.hyperparams['learning_rate']\n",
    "        \n",
    "        # For chained optimizers (like adamw with gradient clipping)\n",
    "        # Navigate the chain to find the schedule\n",
    "        current_state = opt_state\n",
    "        for i in range(10):  # Safety limit\n",
    "            if hasattr(current_state, 'hyperparams'):\n",
    "                if isinstance(current_state.hyperparams, dict) and 'learning_rate' in current_state.hyperparams:\n",
    "                    lr = current_state.hyperparams['learning_rate']\n",
    "                    # If it's a schedule function, call it with the step\n",
    "                    if callable(lr):\n",
    "                        return lr(step)\n",
    "                    return lr\n",
    "                elif hasattr(current_state.hyperparams, 'learning_rate'):\n",
    "                    lr = current_state.hyperparams.learning_rate\n",
    "                    if callable(lr):\n",
    "                        return lr(step)\n",
    "                    return lr\n",
    "            \n",
    "            # Try to go deeper into nested state\n",
    "            if hasattr(current_state, 'inner_state') and len(current_state.inner_state) > 0:\n",
    "                current_state = current_state.inner_state[0]\n",
    "            elif hasattr(current_state, 'inner_state'):\n",
    "                break\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        # Fallback: return a default learning rate\n",
    "        return 5e-5\n",
    "        \n",
    "    except Exception as e:\n",
    "        # If all else fails, return the base learning rate\n",
    "        return 5e-5\n",
    "\n",
    "@jax.jit\n",
    "def enhanced_train_step(train_state_obj, batch_specs, dropout_rng, stochastic_rng):\n",
    "    \"\"\"Enhanced training step with advanced SSAST loss\"\"\"\n",
    "    \n",
    "    def loss_fn(params):\n",
    "        # Forward pass\n",
    "        features = train_state_obj.apply_fn(\n",
    "            params, batch_specs,\n",
    "            training=True,\n",
    "            rngs={'dropout': dropout_rng, 'stochastic_depth': stochastic_rng}\n",
    "        )  # Shape: [batch, num_patches, embed_dim]\n",
    "        \n",
    "        # SSAST Self-Supervised Loss Components:\n",
    "        \n",
    "        # 1. Consistency Loss: Features should be consistent across patches\n",
    "        # Encourage similar features for similar patches\n",
    "        patch_mean = jnp.mean(features, axis=1, keepdims=True)  # [batch, 1, embed_dim]\n",
    "        consistency_loss = jnp.mean(jnp.var(features - patch_mean, axis=1))\n",
    "        \n",
    "        # 2. Magnitude Regularization: Prevent feature explosion\n",
    "        magnitude_loss = jnp.mean(jnp.square(features))\n",
    "        \n",
    "        # 3. Diversity Loss: Encourage diverse representations across embedding dimensions\n",
    "        feature_std = jnp.std(features, axis=(0, 1))  # [embed_dim]\n",
    "        diversity_loss = -jnp.mean(jnp.log(feature_std + 1e-8))  # Encourage high std\n",
    "        \n",
    "        # Combined loss\n",
    "        total_loss = consistency_loss + 0.1 * magnitude_loss + 0.01 * diversity_loss\n",
    "        \n",
    "        # Additional metrics for monitoring\n",
    "        metrics = {\n",
    "            'total_loss': total_loss,\n",
    "            'consistency_loss': consistency_loss,\n",
    "            'magnitude_loss': magnitude_loss,\n",
    "            'diversity_loss': diversity_loss,\n",
    "            'output_mean': jnp.mean(features),\n",
    "            'output_std': jnp.std(features)\n",
    "        }\n",
    "        \n",
    "        return total_loss, metrics\n",
    "    \n",
    "    # Compute gradients\n",
    "    (loss_val, metrics), grads = jax.value_and_grad(loss_fn, has_aux=True)(train_state_obj.params)\n",
    "    \n",
    "    # Gradient norm for monitoring\n",
    "    grad_norm = optax.global_norm(grads)\n",
    "    \n",
    "    # Update parameters\n",
    "    new_train_state = train_state_obj.apply_gradients(grads=grads)\n",
    "    \n",
    "    # Get current learning rate (using safe extraction function)\n",
    "    current_lr = get_learning_rate_from_optimizer(train_state_obj.opt_state, train_state_obj.step)\n",
    "    \n",
    "    # Update metrics\n",
    "    metrics.update({\n",
    "        'grad_norm': grad_norm,\n",
    "        'learning_rate': current_lr\n",
    "    })\n",
    "    \n",
    "    return new_train_state, metrics\n",
    "\n",
    "# Initialize production AST model\n",
    "print(f\"üèóÔ∏è Initializing Production AST Model...\")\n",
    "ast_model = ProductionASTForSSAST(\n",
    "    patch_size=16,\n",
    "    embed_dim=768,\n",
    "    num_layers=12,  # Full 12 layers for production\n",
    "    num_heads=12,   # Full 12 heads\n",
    "    mlp_ratio=4.0,\n",
    "    dropout_rate=0.1,\n",
    "    attention_dropout=0.1,\n",
    "    stochastic_depth_rate=0.1\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Production AST Model Initialized!\")\n",
    "print(f\"   ‚Ä¢ Patch size: 16x16\")\n",
    "print(f\"   ‚Ä¢ Embedding dimension: 768\")\n",
    "print(f\"   ‚Ä¢ Transformer layers: 12\")\n",
    "print(f\"   ‚Ä¢ Attention heads: 12\")\n",
    "print(f\"   ‚Ä¢ MLP ratio: 4.0\")\n",
    "print(f\"   ‚Ä¢ Stochastic depth: 0.1\")\n",
    "print(f\"   ‚Ä¢ Total patches per spectrogram: 64 (8x8)\")\n",
    "\n",
    "# Test model initialization\n",
    "print(f\"\\nüß™ Testing model initialization...\")\n",
    "dummy_input = jnp.ones((2, 128, 128))  # Batch of 2 spectrograms\n",
    "rng = jax.random.PRNGKey(42)\n",
    "init_rng, dropout_rng, stochastic_rng = jax.random.split(rng, 3)\n",
    "\n",
    "params = ast_model.init(\n",
    "    {'params': init_rng, 'dropout': dropout_rng, 'stochastic_depth': stochastic_rng},\n",
    "    dummy_input,\n",
    "    training=False\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "param_count = sum(x.size for x in jax.tree.leaves(params))\n",
    "print(f\"‚úÖ Model initialized successfully!\")\n",
    "print(f\"   ‚Ä¢ Total parameters: {param_count:,}\")\n",
    "print(f\"   ‚Ä¢ Memory usage: ~{param_count * 4 / 1024**2:.1f} MB (FP32)\")\n",
    "\n",
    "# Test forward pass\n",
    "print(f\"\\nüöÄ Testing forward pass...\")\n",
    "output = ast_model.apply(\n",
    "    params, dummy_input,\n",
    "    training=False,\n",
    "    rngs={'dropout': dropout_rng, 'stochastic_depth': stochastic_rng}\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Forward pass successful!\")\n",
    "print(f\"   ‚Ä¢ Input shape: {dummy_input.shape}\")\n",
    "print(f\"   ‚Ä¢ Output shape: {output.shape}\")\n",
    "print(f\"   ‚Ä¢ Output stats: min={output.min():.4f}, max={output.max():.4f}, mean={output.mean():.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ Ready for SSAST pre-training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üöÄ Cell 6: Execute SSAST Pre-training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('./src')\n",
    "\n",
    "print(\"üöÄ SSAST PRE-TRAINING - PRODUCTION EXECUTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check that we have our components ready\n",
    "if 'train_dataset' not in locals():\n",
    "    raise RuntimeError(\"Run Cell 4 first to set up datasets with train/val/test splits\")\n",
    "\n",
    "if 'ast_model' not in locals():\n",
    "    raise RuntimeError(\"Run Cell 5 first to initialize production AST model\")\n",
    "\n",
    "print(\"‚úÖ All prerequisites ready\")\n",
    "print(f\"   ‚Ä¢ Enhanced datasets with augmentation: ‚úÖ\")\n",
    "print(f\"   ‚Ä¢ Production 12-layer AST model: ‚úÖ\") \n",
    "print(f\"   ‚Ä¢ Advanced training pipeline: ‚úÖ\")\n",
    "print(f\"   ‚Ä¢ WandB experiment tracking: ‚úÖ\")\n",
    "\n",
    "def execute_ssast_pretraining(\n",
    "    model, train_dataset, val_dataset, \n",
    "    num_epochs=50, batch_size=32, patience=15\n",
    "):\n",
    "    \"\"\"Execute SSAST pre-training with all improvements\"\"\"\n",
    "    print(\"üöÄ Starting SSAST Pre-training...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Initialize model parameters\n",
    "    rng = jax.random.PRNGKey(42)\n",
    "    rng, init_rng, dropout_rng, stochastic_rng = jax.random.split(rng, 4)\n",
    "    \n",
    "    dummy_input = jnp.ones((batch_size, 128, 128))\n",
    "    params = model.init(\n",
    "        {'params': init_rng, 'dropout': dropout_rng, 'stochastic_depth': stochastic_rng},\n",
    "        dummy_input,\n",
    "        training=False\n",
    "    )\n",
    "    \n",
    "    # Training configuration\n",
    "    train_size = len(train_dataset)\n",
    "    steps_per_epoch = max(train_size // batch_size, 10)\n",
    "    total_steps = num_epochs * steps_per_epoch\n",
    "    \n",
    "    print(f\"üìä Training Configuration:\")\n",
    "    print(f\"   ‚Ä¢ Model: {model.__class__.__name__}\")\n",
    "    print(f\"   ‚Ä¢ Parameters: {sum(x.size for x in jax.tree.leaves(params)):,}\")\n",
    "    print(f\"   ‚Ä¢ Train size: {train_size} spectrograms\")\n",
    "    print(f\"   ‚Ä¢ Val size: {len(val_dataset)} spectrograms\")\n",
    "    print(f\"   ‚Ä¢ Batch size: {batch_size}\")\n",
    "    print(f\"   ‚Ä¢ Steps per epoch: {steps_per_epoch}\")\n",
    "    print(f\"   ‚Ä¢ Total steps: {total_steps:,}\")\n",
    "    print(f\"   ‚Ä¢ Epochs: {num_epochs}\")\n",
    "    print(f\"   ‚Ä¢ Early stopping patience: {patience}\")\n",
    "    \n",
    "    # Create advanced optimizer\n",
    "    optimizer = create_advanced_optimizer(\n",
    "        total_steps=total_steps,\n",
    "        learning_rate=5e-5,\n",
    "        weight_decay=0.01\n",
    "    )\n",
    "    \n",
    "    # Create training state\n",
    "    train_state_obj = train_state.TrainState.create(\n",
    "        apply_fn=model.apply,\n",
    "        params=params,\n",
    "        tx=optimizer\n",
    "    )\n",
    "    \n",
    "    # Training tracking\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    training_history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'learning_rates': [],\n",
    "        'grad_norms': []\n",
    "    }\n",
    "    \n",
    "    # Create checkpoint directory\n",
    "    checkpoint_dir = '/content/drive/MyDrive/piano_transformer/checkpoints/ssast_pretraining'\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\nüéØ Starting training loop...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # === TRAINING PHASE ===\n",
    "        train_metrics = []\n",
    "        \n",
    "        for step in range(steps_per_epoch):\n",
    "            # Get training batch\n",
    "            batch_specs = train_dataset.get_batch(batch_size, shuffle=True)\n",
    "            batch_specs = jnp.array(batch_specs)\n",
    "            \n",
    "            # Generate RNG keys for this step\n",
    "            rng, dropout_rng, stochastic_rng = jax.random.split(rng, 3)\n",
    "            \n",
    "            # Training step\n",
    "            train_state_obj, metrics = enhanced_train_step(\n",
    "                train_state_obj, batch_specs, dropout_rng, stochastic_rng\n",
    "            )\n",
    "            \n",
    "            train_metrics.append(metrics)\n",
    "            \n",
    "            # Log to WandB every 10 steps\n",
    "            if step % 10 == 0:\n",
    "                try:\n",
    "                    wandb.log({\n",
    "                        \"train/loss\": float(metrics['total_loss']),\n",
    "                        \"train/consistency_loss\": float(metrics['consistency_loss']),\n",
    "                        \"train/magnitude_loss\": float(metrics['magnitude_loss']),\n",
    "                        \"train/diversity_loss\": float(metrics['diversity_loss']),\n",
    "                        \"train/output_mean\": float(metrics['output_mean']),\n",
    "                        \"train/output_std\": float(metrics['output_std']),\n",
    "                        \"train/grad_norm\": float(metrics['grad_norm']),\n",
    "                        \"train/learning_rate\": float(metrics['learning_rate']),\n",
    "                        \"epoch\": epoch,\n",
    "                        \"step\": int(train_state_obj.step)\n",
    "                    })\n",
    "                except:\n",
    "                    pass  # Continue if WandB fails\n",
    "        \n",
    "        # === VALIDATION PHASE ===\n",
    "        val_metrics = []\n",
    "        val_steps = max(len(val_dataset) // batch_size, 1)\n",
    "        \n",
    "        for val_step in range(val_steps):\n",
    "            batch_specs = val_dataset.get_batch(batch_size, shuffle=False)\n",
    "            batch_specs = jnp.array(batch_specs)\n",
    "            \n",
    "            # Validation forward pass (no training)\n",
    "            rng, dropout_rng, stochastic_rng = jax.random.split(rng, 3)\n",
    "            \n",
    "            features = model.apply(\n",
    "                train_state_obj.params, batch_specs,\n",
    "                training=False,\n",
    "                rngs={'dropout': dropout_rng, 'stochastic_depth': stochastic_rng}\n",
    "            )\n",
    "            \n",
    "            # Compute validation loss (same as training but without gradients)\n",
    "            patch_mean = jnp.mean(features, axis=1, keepdims=True)\n",
    "            val_consistency_loss = jnp.mean(jnp.var(features - patch_mean, axis=1))\n",
    "            val_magnitude_loss = jnp.mean(jnp.square(features))\n",
    "            feature_std = jnp.std(features, axis=(0, 1))\n",
    "            val_diversity_loss = -jnp.mean(jnp.log(feature_std + 1e-8))\n",
    "            val_loss = val_consistency_loss + 0.1 * val_magnitude_loss + 0.01 * val_diversity_loss\n",
    "            \n",
    "            val_metrics.append({\n",
    "                'val_loss': val_loss,\n",
    "                'val_consistency_loss': val_consistency_loss,\n",
    "                'val_magnitude_loss': val_magnitude_loss,\n",
    "                'val_diversity_loss': val_diversity_loss\n",
    "            })\n",
    "        \n",
    "        # === EPOCH SUMMARY ===\n",
    "        # Average metrics\n",
    "        avg_train_loss = np.mean([m['total_loss'] for m in train_metrics])\n",
    "        avg_val_loss = np.mean([m['val_loss'] for m in val_metrics])\n",
    "        avg_lr = np.mean([m['learning_rate'] for m in train_metrics])\n",
    "        avg_grad_norm = np.mean([m['grad_norm'] for m in train_metrics])\n",
    "        \n",
    "        # Store history\n",
    "        training_history['train_loss'].append(avg_train_loss)\n",
    "        training_history['val_loss'].append(avg_val_loss)\n",
    "        training_history['learning_rates'].append(avg_lr)\n",
    "        training_history['grad_norms'].append(avg_grad_norm)\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:3d}: \"\n",
    "              f\"Train Loss={avg_train_loss:.4f}, \"\n",
    "              f\"Val Loss={avg_val_loss:.4f}, \"\n",
    "              f\"LR={avg_lr:.6f}, \"\n",
    "              f\"Time={epoch_time:.1f}s\")\n",
    "        \n",
    "        # Log epoch metrics to WandB\n",
    "        try:\n",
    "            wandb.log({\n",
    "                \"epoch/train_loss\": avg_train_loss,\n",
    "                \"epoch/val_loss\": avg_val_loss,\n",
    "                \"epoch/learning_rate\": avg_lr,\n",
    "                \"epoch/grad_norm\": avg_grad_norm,\n",
    "                \"epoch/time_seconds\": epoch_time,\n",
    "                \"epoch/total_time_hours\": total_time / 3600,\n",
    "                \"epoch/epoch\": epoch + 1\n",
    "            })\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # === EARLY STOPPING & CHECKPOINTING ===\n",
    "        improved = avg_val_loss < best_val_loss\n",
    "        \n",
    "        if improved:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # Save best model\n",
    "            best_checkpoint = {\n",
    "                'params': train_state_obj.params,\n",
    "                'step': train_state_obj.step,\n",
    "                'epoch': epoch + 1,\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'training_history': training_history,\n",
    "                'model_config': {\n",
    "                    'embed_dim': 768,\n",
    "                    'num_layers': 12,\n",
    "                    'num_heads': 12,\n",
    "                    'patch_size': 16,\n",
    "                    'stochastic_depth_rate': 0.1\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            best_path = os.path.join(checkpoint_dir, 'best_ssast_model.pkl')\n",
    "            with open(best_path, 'wb') as f:\n",
    "                pickle.dump(best_checkpoint, f)\n",
    "            \n",
    "            print(f\"   ‚úÖ New best model saved (val_loss: {best_val_loss:.4f})\")\n",
    "            \n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"   ‚è≥ No improvement ({patience_counter}/{patience})\")\n",
    "        \n",
    "        # Regular checkpoint every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pkl')\n",
    "            regular_checkpoint = {\n",
    "                'params': train_state_obj.params,\n",
    "                'step': train_state_obj.step,\n",
    "                'epoch': epoch + 1,\n",
    "                'val_loss': avg_val_loss,\n",
    "                'training_history': training_history\n",
    "            }\n",
    "            with open(checkpoint_path, 'wb') as f:\n",
    "                pickle.dump(regular_checkpoint, f)\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nüõë Early stopping after {patience} epochs without improvement\")\n",
    "            print(f\"   Best validation loss: {best_val_loss:.4f}\")\n",
    "            break\n",
    "    \n",
    "    # === TRAINING COMPLETE ===\n",
    "    total_training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"üéâ SSAST PRE-TRAINING COMPLETED!\")\n",
    "    print(f\"=\"*60)\n",
    "    print(f\"üìà Final Results:\")\n",
    "    print(f\"   ‚Ä¢ Best validation loss: {best_val_loss:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Total epochs: {epoch + 1}\")\n",
    "    print(f\"   ‚Ä¢ Total steps: {train_state_obj.step:,}\")\n",
    "    print(f\"   ‚Ä¢ Training time: {total_training_time/3600:.1f} hours\")\n",
    "    print(f\"   ‚Ä¢ Final learning rate: {avg_lr:.2e}\")\n",
    "    \n",
    "    return train_state_obj, best_val_loss, training_history\n",
    "\n",
    "# Execute SSAST pre-training\n",
    "try:\n",
    "    print(f\"\\nüéØ Starting SSAST Pre-training on MAESTRO dataset...\")\n",
    "    print(f\"   ‚Ä¢ Using production 12-layer AST architecture\")\n",
    "    print(f\"   ‚Ä¢ Training set: {len(train_dataset)} spectrograms (with augmentation)\")\n",
    "    print(f\"   ‚Ä¢ Validation set: {len(val_dataset)} spectrograms (no augmentation)\")\n",
    "    print(f\"   ‚Ä¢ Advanced optimization with cosine LR scheduling\")\n",
    "    print(f\"   ‚Ä¢ Early stopping with patience=15\")\n",
    "    print(f\"   ‚Ä¢ Comprehensive WandB logging\")\n",
    "    \n",
    "    # Execute training with production settings\n",
    "    final_state, best_loss, history = execute_ssast_pretraining(\n",
    "        model=ast_model,\n",
    "        train_dataset=train_dataset, \n",
    "        val_dataset=val_dataset,\n",
    "        num_epochs=50,   # Reduced from 100 for efficiency, increase as needed\n",
    "        batch_size=32,   # Optimal for most GPUs\n",
    "        patience=15      # Early stopping patience\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüéâ SSAST PRE-TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "    print(f\"=\"*70)\n",
    "    \n",
    "    # Save pre-trained model for fine-tuning\n",
    "    pretrained_model_path = '/content/drive/MyDrive/piano_transformer/checkpoints/ssast_pretraining/pretrained_for_finetuning.pkl'\n",
    "    pretrained_checkpoint = {\n",
    "        'params': final_state.params,\n",
    "        'model_config': {\n",
    "            'embed_dim': 768,\n",
    "            'num_layers': 12,\n",
    "            'num_heads': 12,\n",
    "            'patch_size': 16,\n",
    "            'stochastic_depth_rate': 0.1\n",
    "        },\n",
    "        'pretraining_results': {\n",
    "            'best_val_loss': float(best_loss),\n",
    "            'total_epochs': len(history['train_loss']),\n",
    "            'convergence_achieved': best_loss < 1.0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(pretrained_model_path, 'wb') as f:\n",
    "        pickle.dump(pretrained_checkpoint, f)\n",
    "    \n",
    "    print(f\"üíæ Pre-trained model saved for fine-tuning: {pretrained_model_path}\")\n",
    "    print(f\"üéØ READY FOR FINE-TUNING PHASE!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå SSAST pre-training failed: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Pre-training Complete!\n",
    "\n",
    "**Next Steps:**\n",
    "1. üéØ **Fine-tuning**: Run `2_Piano_Transformer_Finetuning.ipynb` to fine-tune on PercePiano dataset\n",
    "2. üìä **Evaluation**: Run `3_Piano_Transformer_Evaluation.ipynb` to evaluate performance\n",
    "\n",
    "**Pre-trained Model Location:**\n",
    "```\n",
    "/content/drive/MyDrive/piano_transformer/checkpoints/ssast_pretraining/pretrained_for_finetuning.pkl\n",
    "```\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
