{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéπ Piano Perception Transformer - Fine-tuning\n",
    "\n",
    "**Phase 2: Supervised Fine-tuning on PercePiano Dataset**\n",
    "\n",
    "This notebook implements supervised fine-tuning of the pre-trained AST model on the PercePiano dataset to predict 19 perceptual dimensions of piano performance.\n",
    "\n",
    "**Pipeline Overview:**\n",
    "1. üîß **Setup & Environment** - Dependencies, WandB tracking, JAX configuration\n",
    "2. üìä **PercePiano Data Loading** - MIDI to spectrogram conversion and labeling\n",
    "3. üß† **Model Architecture** - Load pre-trained AST and add regression head\n",
    "4. üéØ **Supervised Fine-tuning** - Train on perceptual prediction task\n",
    "5. üíæ **Save Fine-tuned Model** - Checkpoint for evaluation\n",
    "\n",
    "**Input:** Pre-trained AST model from Phase 1  \n",
    "**Output:** Fine-tuned model ready for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîß Cell 1: Setup with WandB Integration\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"üöÄ Setting up Piano Perception Transformer - Fine-tuning Phase...\")\n\n# Clone repo (skip if already exists)\nimport os\nif not os.path.exists('piano-perception-transformer'):\n    !git clone https://github.com/Jai-Dhiman/piano-perception-transformer.git\nelse:\n    print(\"Repository already exists, skipping clone...\")\n\n%cd piano-perception-transformer\n\n# Install uv\n!curl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Install enhanced dependencies including ML research tools\nprint(\"üì¶ Installing enhanced dependencies with uv...\")\n!export PATH=\"/usr/local/bin:$PATH\" && uv pip install --system jax[tpu] flax optax librosa pandas wandb requests zipfile36 scikit-learn scipy seaborn matplotlib pretty_midi soundfile\n\n# Import core libraries\nimport sys\nimport json\nimport pickle\nimport numpy as np\nimport jax\nimport jax.numpy as jnp\nimport optax\nfrom datetime import datetime\nfrom flax import linen as nn\nfrom flax.training import train_state\nimport time\n\n# Initialize WandB for fine-tuning tracking\nimport wandb\n\ntry:\n    wandb.login()  # This will prompt for API key in Colab\n    \n    run = wandb.init(\n        project=\"piano-perception-transformer-finetuning\",\n        name=f\"ast-finetuning-{datetime.now().strftime('%Y%m%d-%H%M')}\",\n        config={\n            \"phase\": \"supervised_finetuning\",\n            \"architecture\": \"Pre-trained AST + Regression Head\",\n            \"model_layers\": 12,\n            \"embed_dim\": 768,\n            \"num_heads\": 12,\n            \"patch_size\": 16,\n            \"learning_rate\": 1e-4,  # Lower LR for fine-tuning\n            \"batch_size\": 16,\n            \"dropout\": 0.1,\n            \"dataset\": \"PercePiano\",\n            \"target_dimensions\": 19,\n            \"experiment_type\": \"supervised_finetuning\",\n            \"loss_function\": \"mse_with_correlation\"\n        },\n        tags=[\"finetuning\", \"ast\", \"percepiano\", \"supervised\", \"regression\"]\n    )\n    \n    print(\"‚úÖ WandB initialized successfully!\")\n    print(f\"   ‚Ä¢ Project: piano-perception-transformer-finetuning\")\n    print(f\"   ‚Ä¢ Run name: {run.name}\")\n    print(f\"   ‚Ä¢ Tracking: https://wandb.ai/{run.entity}/{run.project}/runs/{run.id}\")\n    \nexcept Exception as e:\n    print(f\"‚ö†Ô∏è WandB initialization failed: {e}\")\n    print(\"   ‚Ä¢ Continuing without experiment tracking\")\n    print(\"   ‚Ä¢ Set up WandB API key: https://wandb.ai/settings\")\n\n# Mount Google Drive\nfrom google.colab import drive\nprint(\"üîó Mounting Google Drive...\")\ndrive.mount('/content/drive')\n\n# Create directory structure\nbase_dir = '/content/drive/MyDrive/piano_transformer'\ndirectories = [\n    f'{base_dir}/processed_spectrograms',\n    f'{base_dir}/checkpoints/finetuning',\n    f'{base_dir}/logs',\n    f'{base_dir}/temp'\n]\n\nprint(\"üìÅ Setting up directory structure...\")\nfor directory in directories:\n    os.makedirs(directory, exist_ok=True)\n    print(f\"‚úÖ Created: {directory}\")\n\n# Verify JAX setup\nprint(f\"\\nüß† JAX Configuration:\")\nprint(f\"   ‚Ä¢ Backend: {jax.default_backend()}\")\nprint(f\"   ‚Ä¢ Devices: {jax.device_count()}\")\nprint(f\"   ‚Ä¢ Device type: {jax.devices()[0].device_kind}\")\n\nprint(\"\\n‚úÖ Fine-tuning setup completed!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Cell 2: PercePiano Data Loading and Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clone and setup PercePiano dataset\nprint(\"üìÇ Setting up PercePiano dataset...\")\n\n# Define PercePiano directory path\npercepiano_dir = '/content/drive/MyDrive/PercePiano'\n\n# Clone PercePiano dataset if not exists\nif not os.path.exists(percepiano_dir):\n    print(\"üì• Cloning PercePiano dataset repository...\")\n    !git clone https://github.com/JonghoKimSNU/PercePiano.git {percepiano_dir}\n    print(\"‚úÖ PercePiano dataset cloned successfully!\")\nelse:\n    print(\"‚úÖ PercePiano dataset already exists\")\n\n# Verify essential directory structure\nrequired_paths = [\n    f'{percepiano_dir}/labels/label_2round_mean_reg_19_with0_rm_highstd0.json',\n    f'{percepiano_dir}/virtuoso/data/all_2rounds'\n]\n\nprint(\"üîç Verifying dataset structure...\")\nmissing_paths = []\nfor path in required_paths:\n    if not os.path.exists(path):\n        missing_paths.append(path)\n    else:\n        if path.endswith('.json'):\n            print(f\"   ‚úÖ Labels file found: {os.path.basename(path)}\")\n        else:\n            midi_count = len([f for f in os.listdir(path) if f.endswith('.mid')])\n            print(f\"   ‚úÖ MIDI directory found: {midi_count} MIDI files\")\n\nif missing_paths:\n    print(\"‚ùå Missing required files/directories:\")\n    for path in missing_paths:\n        print(f\"   ‚Ä¢ {path}\")\n    print(\"\\nüí° The dataset may need to be downloaded separately.\")\n    print(\"   Please refer to the PercePiano repository instructions.\")\n    raise FileNotFoundError(\"PercePiano dataset structure incomplete\")\n\nprint(\"‚úÖ Dataset structure verified successfully!\")\n\nimport json\nimport numpy as np\nimport pretty_midi\nimport librosa\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\ndef midi_to_spectrogram(midi_path, sr=22050, n_mels=128, hop_length=512, n_fft=2048, target_length=128):\n    \"\"\"\n    Enhanced MIDI to mel-spectrogram converter with better synthesis\n    \n    Args:\n        midi_path: Path to MIDI file\n        sr: Sample rate for audio synthesis\n        n_mels: Number of mel frequency bins\n        hop_length: Hop length for STFT\n        n_fft: FFT size\n        target_length: Fixed time dimension for output spectrogram\n    \n    Returns:\n        mel_spectrogram: [time, freq] mel-spectrogram with shape (target_length, n_mels)\n    \"\"\"\n    try:\n        # Load MIDI file\n        midi_data = pretty_midi.PrettyMIDI(midi_path)\n        \n        # Enhanced synthesis with better defaults\n        try:\n            audio = midi_data.fluidsynth(fs=sr)  # Use fluidsynth if available\n        except:\n            audio = midi_data.synthesize(fs=sr)  # Fallback to basic synthesis\n        \n        # Ensure minimum audio length\n        min_duration = 2.0  # seconds\n        min_samples = int(min_duration * sr)\n        if len(audio) < min_samples:\n            # Pad with silence\n            padding = min_samples - len(audio)\n            audio = np.pad(audio, (0, padding), mode='constant')\n        \n        # Convert to mel-spectrogram\n        mel_spec = librosa.feature.melspectrogram(\n            y=audio,\n            sr=sr,\n            n_mels=n_mels,\n            hop_length=hop_length,\n            n_fft=n_fft,\n            power=2.0,\n            fmin=20,  # Lower frequency bound\n            fmax=sr//2  # Nyquist frequency\n        )\n        \n        # Convert to log scale\n        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n        \n        # Transpose to [time, freq] format\n        mel_spec_transposed = mel_spec_db.T  # Shape: (time, freq)\n        \n        # Normalize to fixed time dimension\n        current_length = mel_spec_transposed.shape[0]\n        \n        if current_length >= target_length:\n            # Truncate to target length\n            normalized_spec = mel_spec_transposed[:target_length, :]\n        else:\n            # Pad to target length\n            pad_width = target_length - current_length\n            normalized_spec = np.pad(\n                mel_spec_transposed, \n                ((0, pad_width), (0, 0)), \n                mode='constant', \n                constant_values=-80.0  # Use a reasonable silence value in dB scale\n            )\n        \n        return normalized_spec\n        \n    except Exception as e:\n        print(f\"Error converting MIDI {midi_path}: {str(e)}\")\n        return None\n\ndef load_percepiano_data(percepiano_dir):\n    \"\"\"Load PercePiano dataset with MIDI-to-spectrogram conversion\"\"\"\n    labels_file = f'{percepiano_dir}/labels/label_2round_mean_reg_19_with0_rm_highstd0.json'\n    \n    print(f\"üìã Loading labels from: {labels_file}\")\n    with open(labels_file, 'r') as f:\n        labels_data = json.load(f)\n\n    if len(labels_data) == 0:\n        raise ValueError(\"Labels file is empty\")\n\n    print(f\"üìä Loaded PercePiano labels: {len(labels_data)} samples\")\n\n    # Load MIDI files and convert to spectrograms\n    midi_dir = f'{percepiano_dir}/virtuoso/data/all_2rounds'\n    \n    if not os.path.exists(midi_dir):\n        raise FileNotFoundError(f\"MIDI directory not found: {midi_dir}\")\n    \n    midi_files = [f for f in os.listdir(midi_dir) if f.endswith('.mid')]\n\n    if len(midi_files) == 0:\n        raise FileNotFoundError(f\"No MIDI files found in: {midi_dir}\")\n\n    print(f\"üéµ Found {len(midi_files)} MIDI files\")\n\n    samples = []\n    processed_count = 0\n\n    for filename, label_data in labels_data.items():\n        # Find corresponding MIDI file (flexible matching)\n        midi_filename = None\n        for midi_file in midi_files:\n            # Try multiple matching strategies\n            if (filename in midi_file or \n                midi_file.replace('.mid', '') in filename or\n                filename.replace('.mid', '') in midi_file.replace('.mid', '')):\n                midi_filename = midi_file\n                break\n\n        if midi_filename is None:\n            print(f\"‚ö†Ô∏è MIDI file not found for label: {filename}\")\n            continue\n\n        # Extract the 19 perceptual features\n        if isinstance(label_data, list) and len(label_data) >= 19:\n            perceptual_features = np.array(label_data[:19], dtype=np.float32)\n        else:\n            print(f\"‚ö†Ô∏è Insufficient label data for {filename}: expected 19 features, got {len(label_data) if isinstance(label_data, list) else 'non-list'}\")\n            continue\n\n        # Convert MIDI to spectrogram with fixed dimensions\n        midi_path = os.path.join(midi_dir, midi_filename)\n        spectrogram = midi_to_spectrogram(\n            midi_path, \n            sr=22050, \n            n_mels=128, \n            hop_length=512,\n            n_fft=2048,\n            target_length=128  # Match MAESTRO preprocessing\n        )\n        \n        if spectrogram is not None:\n            # Verify expected shape\n            expected_shape = (128, 128)  # (time, freq)\n            if spectrogram.shape != expected_shape:\n                print(f\"‚ö†Ô∏è Unexpected spectrogram shape for {midi_filename}: {spectrogram.shape}, expected {expected_shape}\")\n                continue\n                \n            samples.append({\n                'spectrogram': spectrogram,\n                'labels': perceptual_features,\n                'filename': filename\n            })\n            processed_count += 1\n            \n            # Print progress every 25 files\n            if processed_count % 25 == 0:\n                print(f\"üìä Processed {processed_count} samples...\")\n        else:\n            print(f\"‚ö†Ô∏è Failed to convert MIDI: {midi_filename}\")\n            continue\n\n    if processed_count == 0:\n        raise ValueError(\"No samples were successfully processed\")\n\n    print(f\"‚úÖ Successfully processed {processed_count} samples\")\n    return samples\n\nclass PercePianoDataset:\n    \"\"\"PercePiano dataset with train/val/test splits and label normalization\"\"\"\n    \n    def __init__(self, samples, split='train', train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, random_seed=42):\n        self.split = split\n        self.random_seed = random_seed\n        \n        # Validate split ratios\n        assert abs((train_ratio + val_ratio + test_ratio) - 1.0) < 1e-6, \"Split ratios must sum to 1.0\"\n        \n        # Create reproducible train/val/test splits\n        np.random.seed(random_seed)\n        \n        # Extract spectrograms and labels\n        spectrograms = [s['spectrogram'] for s in samples]\n        labels = [s['labels'] for s in samples]\n        filenames = [s['filename'] for s in samples]\n        \n        # First split: train vs (val + test)\n        train_specs, temp_specs, train_labels, temp_labels, train_files, temp_files = train_test_split(\n            spectrograms, labels, filenames,\n            test_size=(val_ratio + test_ratio), \n            random_state=random_seed,\n            stratify=None  # Can't stratify continuous labels easily\n        )\n        \n        # Second split: val vs test\n        val_size = val_ratio / (val_ratio + test_ratio)\n        val_specs, test_specs, val_labels, test_labels, val_files, test_files = train_test_split(\n            temp_specs, temp_labels, temp_files,\n            test_size=(1 - val_size), \n            random_state=random_seed\n        )\n        \n        # Assign data based on split\n        if split == 'train':\n            self.spectrograms = np.array(train_specs)\n            self.labels = np.array(train_labels)\n            self.filenames = train_files\n        elif split == 'val':\n            self.spectrograms = np.array(val_specs)\n            self.labels = np.array(val_labels)\n            self.filenames = val_files\n        elif split == 'test':\n            self.spectrograms = np.array(test_specs)\n            self.labels = np.array(test_labels)\n            self.filenames = test_files\n        else:\n            raise ValueError(f\"Invalid split: {split}. Must be 'train', 'val', or 'test'\")\n        \n        self.num_samples = len(self.spectrograms)\n        \n        print(f\"üìä PercePiano Split Statistics:\")\n        print(f\"   ‚Ä¢ Train: {len(train_specs)} samples ({len(train_specs)/len(samples)*100:.1f}%)\")\n        print(f\"   ‚Ä¢ Val:   {len(val_specs)} samples ({len(val_specs)/len(samples)*100:.1f}%)\")\n        print(f\"   ‚Ä¢ Test:  {len(test_specs)} samples ({len(test_specs)/len(samples)*100:.1f}%)\")\n        print(f\"   ‚Ä¢ Using: {self.num_samples} samples for '{split}' split\")\n        \n        # Label normalization (fit on training data only)\n        if split == 'train':\n            self.label_scaler = StandardScaler()\n            self.labels = self.label_scaler.fit_transform(self.labels)\n            print(f\"‚úÖ Label scaler fitted on training data\")\n            print(f\"   ‚Ä¢ Original label stats: mean={np.mean(train_labels, axis=0)[:3]}, std={np.std(train_labels, axis=0)[:3]}\")\n            print(f\"   ‚Ä¢ Normalized label stats: mean={np.mean(self.labels, axis=0)[:3]}, std={np.std(self.labels, axis=0)[:3]}\")\n        else:\n            self.label_scaler = None  # Will be set externally\n    \n    def set_label_scaler(self, scaler):\n        \"\"\"Set the label scaler for val/test splits\"\"\"\n        self.label_scaler = scaler\n        self.labels = scaler.transform(self.labels)\n        print(f\"‚úÖ Applied label normalization to {self.split} split\")\n    \n    def __len__(self):\n        return self.num_samples\n    \n    def get_batch(self, batch_size, shuffle=None):\n        \"\"\"Get a batch of spectrograms and labels\"\"\"\n        if shuffle is None:\n            shuffle = (self.split == 'train')\n        \n        if shuffle:\n            indices = np.random.choice(self.num_samples, size=batch_size, replace=True)\n        else:\n            start_idx = np.random.randint(0, max(1, self.num_samples - batch_size + 1))\n            indices = np.arange(start_idx, start_idx + batch_size) % self.num_samples\n        \n        batch_specs = self.spectrograms[indices]\n        batch_labels = self.labels[indices]\n        \n        return batch_specs, batch_labels\n\n# Load PercePiano dataset\nprint(\"\\nüîÑ Loading and processing PercePiano dataset...\")\n\ntry:\n    # Load raw data\n    raw_samples = load_percepiano_data(percepiano_dir)\n    \n    # Create dataset splits\n    train_dataset = PercePianoDataset(raw_samples, split='train', random_seed=42)\n    val_dataset = PercePianoDataset(raw_samples, split='val', random_seed=42)\n    test_dataset = PercePianoDataset(raw_samples, split='test', random_seed=42)\n    \n    # Apply label normalization to val/test sets\n    val_dataset.set_label_scaler(train_dataset.label_scaler)\n    test_dataset.set_label_scaler(train_dataset.label_scaler)\n    \n    print(f\"\\n‚úÖ PercePiano datasets created successfully!\")\n    print(f\"   ‚Ä¢ Training dataset: {len(train_dataset)} samples\")\n    print(f\"   ‚Ä¢ Validation dataset: {len(val_dataset)} samples\")\n    print(f\"   ‚Ä¢ Test dataset: {len(test_dataset)} samples\")\n    \n    # Test batch loading\n    print(f\"\\nüß™ Testing data pipeline...\")\n    train_specs, train_labels = train_dataset.get_batch(4)\n    val_specs, val_labels = val_dataset.get_batch(4)\n    \n    print(f\"   ‚Ä¢ Train batch specs shape: {train_specs.shape}\")\n    print(f\"   ‚Ä¢ Train batch labels shape: {train_labels.shape}\")\n    print(f\"   ‚Ä¢ Val batch specs shape: {val_specs.shape}\")\n    print(f\"   ‚Ä¢ Val batch labels shape: {val_labels.shape}\")\n    print(f\"   ‚Ä¢ Label stats (normalized): min={train_labels.min():.2f}, max={train_labels.max():.2f}, mean={train_labels.mean():.2f}\")\n    \n    print(f\"\\nüéØ Ready for supervised fine-tuning!\")\n    \nexcept Exception as e:\n    print(f\"‚ùå PercePiano data loading failed: {e}\")\n    print(f\"   Error details: {str(e)}\")\n    print(f\"\\nüí° Troubleshooting tips:\")\n    print(f\"   1. Check if PercePiano repository was cloned correctly\")\n    print(f\"   2. Verify internet connection for cloning\")\n    print(f\"   3. Ensure sufficient disk space in Google Drive\")\n    raise Exception(f\"PercePiano dataset setup failed: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üß† Cell 3: Load Pre-trained Model and Add Regression Head\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "from flax import traverse_util\n",
    "import time\n",
    "\n",
    "sys.path.append('/content/piano-perception-transformer/src')\n",
    "\n",
    "print(\"üß† Loading Pre-trained AST and Creating Regression Model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class ProductionASTForRegression(nn.Module):\n",
    "    \"\"\"AST model with regression head for perceptual prediction\n",
    "    \n",
    "    Loads pre-trained AST backbone and adds a regression head for 19 perceptual dimensions\n",
    "    \"\"\"\n",
    "    \n",
    "    patch_size: int = 16\n",
    "    embed_dim: int = 768\n",
    "    num_layers: int = 12\n",
    "    num_heads: int = 12\n",
    "    mlp_ratio: float = 4.0\n",
    "    dropout_rate: float = 0.1\n",
    "    attention_dropout: float = 0.1\n",
    "    stochastic_depth_rate: float = 0.1\n",
    "    num_outputs: int = 19  # 19 perceptual dimensions\n",
    "    \n",
    "    def setup(self):\n",
    "        # Pre-compute stochastic depth drop rates (linearly increasing)\n",
    "        self.drop_rates = [\n",
    "            self.stochastic_depth_rate * i / (self.num_layers - 1) \n",
    "            for i in range(self.num_layers)\n",
    "        ]\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x, training: bool = True):\n",
    "        \"\"\"\n",
    "        Full AST forward pass with regression head\n",
    "        Args:\n",
    "            x: Mel-spectrogram [batch, time, freq] -> (batch, 128, 128)\n",
    "        Returns:\n",
    "            predictions: [batch, 19] regression outputs for perceptual dimensions\n",
    "        \"\"\"\n",
    "        batch_size, time_frames, freq_bins = x.shape\n",
    "        \n",
    "        # === PATCH EMBEDDING ===\n",
    "        patch_size = self.patch_size\n",
    "        \n",
    "        # Ensure input can be divided into patches  \n",
    "        time_pad = (patch_size - time_frames % patch_size) % patch_size\n",
    "        freq_pad = (patch_size - freq_bins % patch_size) % patch_size\n",
    "        \n",
    "        if time_pad > 0 or freq_pad > 0:\n",
    "            x = jnp.pad(x, ((0, 0), (0, time_pad), (0, freq_pad)), mode='constant', constant_values=-80.0)\n",
    "        \n",
    "        time_patches = x.shape[1] // patch_size\n",
    "        freq_patches = x.shape[2] // patch_size\n",
    "        num_patches = time_patches * freq_patches\n",
    "        \n",
    "        # Reshape to patches: [batch, num_patches, patch_dim]\n",
    "        x = x.reshape(batch_size, time_patches, patch_size, freq_patches, patch_size)\n",
    "        x = x.transpose(0, 1, 3, 2, 4)\n",
    "        x = x.reshape(batch_size, num_patches, patch_size * patch_size)\n",
    "        \n",
    "        # Linear patch embedding (pre-trained)\n",
    "        x = nn.Dense(\n",
    "            self.embed_dim, \n",
    "            kernel_init=nn.initializers.truncated_normal(stddev=0.02),\n",
    "            bias_init=nn.initializers.zeros,\n",
    "            name='patch_embedding'\n",
    "        )(x)\n",
    "        \n",
    "        # === 2D POSITIONAL ENCODING (pre-trained) ===\n",
    "        pos_embedding = self.param(\n",
    "            'pos_embedding',\n",
    "            nn.initializers.truncated_normal(stddev=0.02),\n",
    "            (1, num_patches, self.embed_dim)\n",
    "        )\n",
    "        x = x + pos_embedding\n",
    "        \n",
    "        # Embedding dropout\n",
    "        x = nn.Dropout(self.dropout_rate, deterministic=not training)(x)\n",
    "        \n",
    "        # === 12-LAYER TRANSFORMER ENCODER (pre-trained) ===\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            # Stochastic depth probability for this layer\n",
    "            drop_rate = self.drop_rates[layer_idx]\n",
    "            \n",
    "            # Multi-Head Self-Attention Block\n",
    "            residual = x\n",
    "            x = nn.LayerNorm(epsilon=1e-6, name=f'norm1_layer{layer_idx}')(x)\n",
    "            \n",
    "            attention = nn.MultiHeadDotProductAttention(\n",
    "                num_heads=self.num_heads,\n",
    "                dropout_rate=self.attention_dropout,\n",
    "                kernel_init=nn.initializers.truncated_normal(stddev=0.02),\n",
    "                bias_init=nn.initializers.zeros,\n",
    "                name=f'attention_layer{layer_idx}'\n",
    "            )(x, x, deterministic=not training)\n",
    "            \n",
    "            # Stochastic depth for attention (training only)\n",
    "            if training and drop_rate > 0:\n",
    "                random_tensor = jax.random.uniform(\n",
    "                    self.make_rng('stochastic_depth'), (batch_size, 1, 1)\n",
    "                )\n",
    "                keep_prob = 1.0 - drop_rate\n",
    "                binary_tensor = (random_tensor < keep_prob).astype(x.dtype)\n",
    "                attention = attention * binary_tensor / keep_prob\n",
    "            \n",
    "            x = residual + nn.Dropout(self.dropout_rate, deterministic=not training)(attention)\n",
    "            \n",
    "            # Feed-Forward Network Block\n",
    "            residual = x\n",
    "            x = nn.LayerNorm(epsilon=1e-6, name=f'norm2_layer{layer_idx}')(x)\n",
    "            \n",
    "            # MLP with 4x expansion\n",
    "            mlp_hidden = int(self.embed_dim * self.mlp_ratio)\n",
    "            \n",
    "            mlp = nn.Dense(\n",
    "                mlp_hidden, \n",
    "                kernel_init=nn.initializers.truncated_normal(stddev=0.02),\n",
    "                bias_init=nn.initializers.zeros,\n",
    "                name=f'mlp_dense1_layer{layer_idx}'\n",
    "            )(x)\n",
    "            mlp = nn.gelu(mlp)\n",
    "            mlp = nn.Dropout(self.dropout_rate, deterministic=not training)(mlp)\n",
    "            \n",
    "            mlp = nn.Dense(\n",
    "                self.embed_dim,\n",
    "                kernel_init=nn.initializers.truncated_normal(stddev=0.02),\n",
    "                bias_init=nn.initializers.zeros,\n",
    "                name=f'mlp_dense2_layer{layer_idx}'\n",
    "            )(mlp)\n",
    "            \n",
    "            # Stochastic depth for MLP\n",
    "            if training and drop_rate > 0:\n",
    "                random_tensor = jax.random.uniform(\n",
    "                    self.make_rng('stochastic_depth'), (batch_size, 1, 1)\n",
    "                )\n",
    "                keep_prob = 1.0 - drop_rate\n",
    "                binary_tensor = (random_tensor < keep_prob).astype(x.dtype)\n",
    "                mlp = mlp * binary_tensor / keep_prob\n",
    "            \n",
    "            x = residual + nn.Dropout(self.dropout_rate, deterministic=not training)(mlp)\n",
    "        \n",
    "        # === FINAL NORMALIZATION (pre-trained) ===\n",
    "        x = nn.LayerNorm(epsilon=1e-6, name='final_norm')(x)\n",
    "        \n",
    "        # === REGRESSION HEAD (new, trainable) ===\n",
    "        # Global average pooling over patches\n",
    "        x = jnp.mean(x, axis=1)  # [batch, embed_dim]\n",
    "        \n",
    "        # Regression layers\n",
    "        x = nn.Dense(\n",
    "            512, \n",
    "            kernel_init=nn.initializers.truncated_normal(stddev=0.02),\n",
    "            bias_init=nn.initializers.zeros,\n",
    "            name='regression_hidden'\n",
    "        )(x)\n",
    "        x = nn.gelu(x)\n",
    "        x = nn.Dropout(self.dropout_rate, deterministic=not training)(x)\n",
    "        \n",
    "        # Final prediction layer\n",
    "        predictions = nn.Dense(\n",
    "            self.num_outputs,\n",
    "            kernel_init=nn.initializers.truncated_normal(stddev=0.02),\n",
    "            bias_init=nn.initializers.zeros,\n",
    "            name='regression_output'\n",
    "        )(x)\n",
    "        \n",
    "        return predictions  # [batch, 19]\n",
    "\n",
    "def load_pretrained_weights(model, checkpoint_path):\n",
    "    \"\"\"Load pre-trained weights from SSAST checkpoint\"\"\"\n",
    "    print(f\"üìÇ Loading pre-trained checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    try:\n",
    "        with open(checkpoint_path, 'rb') as f:\n",
    "            checkpoint = pickle.load(f)\n",
    "        \n",
    "        pretrained_params = checkpoint['params']\n",
    "        print(f\"‚úÖ Pre-trained checkpoint loaded successfully\")\n",
    "        print(f\"   ‚Ä¢ Checkpoint epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "        print(f\"   ‚Ä¢ Checkpoint loss: {checkpoint.get('best_val_loss', 'N/A')}\")\n",
    "        \n",
    "        return pretrained_params, checkpoint\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load pre-trained checkpoint: {e}\")\n",
    "        raise\n",
    "\n",
    "def transfer_pretrained_weights(pretrained_params, new_params):\n",
    "    \"\"\"Transfer pre-trained weights to new model with regression head\"\"\"\n",
    "    print(\"üîÑ Transferring pre-trained weights...\")\n",
    "    \n",
    "    # Flatten parameter trees for easier manipulation\n",
    "    flat_pretrained = traverse_util.flatten_dict(pretrained_params)\n",
    "    flat_new = traverse_util.flatten_dict(new_params)\n",
    "    \n",
    "    transferred_count = 0\n",
    "    new_count = 0\n",
    "    \n",
    "    for key in flat_new:\n",
    "        if key in flat_pretrained:\n",
    "            # Transfer pre-trained weight\n",
    "            flat_new[key] = flat_pretrained[key]\n",
    "            transferred_count += 1\n",
    "        else:\n",
    "            # Keep randomly initialized weight (regression head)\n",
    "            new_count += 1\n",
    "    \n",
    "    # Reconstruct parameter tree\n",
    "    final_params = traverse_util.unflatten_dict(flat_new)\n",
    "    \n",
    "    print(f\"‚úÖ Weight transfer completed:\")\n",
    "    print(f\"   ‚Ä¢ Transferred parameters: {transferred_count}\")\n",
    "    print(f\"   ‚Ä¢ New parameters (regression head): {new_count}\")\n",
    "    \n",
    "    return final_params\n",
    "\n",
    "def create_finetuning_optimizer(total_steps, learning_rate=1e-4, weight_decay=0.01, warmup_steps=500):\n",
    "    \"\"\"Create optimizer for fine-tuning with lower learning rate\"\"\"\n",
    "    \n",
    "    # Warmup + cosine decay schedule\n",
    "    warmup_schedule = optax.linear_schedule(\n",
    "        init_value=1e-8,\n",
    "        end_value=learning_rate,\n",
    "        transition_steps=warmup_steps\n",
    "    )\n",
    "    \n",
    "    cosine_schedule = optax.cosine_decay_schedule(\n",
    "        init_value=learning_rate,\n",
    "        decay_steps=total_steps - warmup_steps,\n",
    "        alpha=0.1  # Final LR = 10% of initial LR for fine-tuning\n",
    "    )\n",
    "    \n",
    "    lr_schedule = optax.join_schedules(\n",
    "        schedules=[warmup_schedule, cosine_schedule],\n",
    "        boundaries=[warmup_steps]\n",
    "    )\n",
    "    \n",
    "    # AdamW optimizer with gradient clipping\n",
    "    optimizer = optax.chain(\n",
    "        optax.clip_by_global_norm(0.5),  # Lower gradient clipping for fine-tuning\n",
    "        optax.adamw(\n",
    "            learning_rate=lr_schedule,\n",
    "            weight_decay=weight_decay,\n",
    "            b1=0.9,\n",
    "            b2=0.999,\n",
    "            eps=1e-8\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return optimizer\n",
    "\n",
    "@jax.jit\n",
    "def compute_correlation(predictions, targets):\n",
    "    \"\"\"Compute Pearson correlation between predictions and targets\"\"\"\n",
    "    # Center the data\n",
    "    pred_centered = predictions - jnp.mean(predictions, axis=0, keepdims=True)\n",
    "    target_centered = targets - jnp.mean(targets, axis=0, keepdims=True)\n",
    "    \n",
    "    # Compute correlation\n",
    "    numerator = jnp.sum(pred_centered * target_centered, axis=0)\n",
    "    pred_norm = jnp.sqrt(jnp.sum(pred_centered**2, axis=0))\n",
    "    target_norm = jnp.sqrt(jnp.sum(target_centered**2, axis=0))\n",
    "    \n",
    "    correlation = numerator / (pred_norm * target_norm + 1e-8)\n",
    "    \n",
    "    return jnp.mean(correlation)  # Average correlation across dimensions\n",
    "\n",
    "@jax.jit\n",
    "def finetuning_train_step(train_state_obj, batch_specs, batch_labels, dropout_rng, stochastic_rng):\n",
    "    \"\"\"Training step for fine-tuning with regression loss\"\"\"\n",
    "    \n",
    "    def loss_fn(params):\n",
    "        # Forward pass\n",
    "        predictions = train_state_obj.apply_fn(\n",
    "            params, batch_specs,\n",
    "            training=True,\n",
    "            rngs={'dropout': dropout_rng, 'stochastic_depth': stochastic_rng}\n",
    "        )\n",
    "        \n",
    "        # MSE loss\n",
    "        mse_loss = jnp.mean(jnp.square(predictions - batch_labels))\n",
    "        \n",
    "        # Correlation-based loss (negative correlation to maximize)\n",
    "        correlation = compute_correlation(predictions, batch_labels)\n",
    "        correlation_loss = -correlation  # Negative to maximize correlation\n",
    "        \n",
    "        # Combined loss\n",
    "        total_loss = mse_loss + 0.1 * correlation_loss\n",
    "        \n",
    "        # Metrics for monitoring\n",
    "        metrics = {\n",
    "            'total_loss': total_loss,\n",
    "            'mse_loss': mse_loss,\n",
    "            'correlation': correlation,\n",
    "            'prediction_mean': jnp.mean(predictions),\n",
    "            'prediction_std': jnp.std(predictions),\n",
    "            'target_mean': jnp.mean(batch_labels),\n",
    "            'target_std': jnp.std(batch_labels)\n",
    "        }\n",
    "        \n",
    "        return total_loss, metrics\n",
    "    \n",
    "    # Compute gradients\n",
    "    (loss_val, metrics), grads = jax.value_and_grad(loss_fn, has_aux=True)(train_state_obj.params)\n",
    "    \n",
    "    # Gradient norm for monitoring\n",
    "    grad_norm = optax.global_norm(grads)\n",
    "    \n",
    "    # Update parameters\n",
    "    new_train_state = train_state_obj.apply_gradients(grads=grads)\n",
    "    \n",
    "    # Get current learning rate - safe extraction from chained optimizer\n",
    "    try:\n",
    "        # For optax.chain() with adamw as the second transformation\n",
    "        current_lr = train_state_obj.opt_state[1].hyperparams['learning_rate']\n",
    "    except (AttributeError, KeyError, IndexError):\n",
    "        try:\n",
    "            # Alternative: try accessing from inner state\n",
    "            current_lr = train_state_obj.tx.inner_state[1].hyperparams['learning_rate']\n",
    "        except (AttributeError, KeyError, IndexError):\n",
    "            # Fallback: use step-based approximation\n",
    "            current_lr = 1e-4  # Default learning rate\n",
    "    \n",
    "    # Update metrics\n",
    "    metrics.update({\n",
    "        'grad_norm': grad_norm,\n",
    "        'learning_rate': current_lr\n",
    "    })\n",
    "    \n",
    "    return new_train_state, metrics\n",
    "\n",
    "# Load pre-trained model and create regression model\n",
    "print(f\"üèóÔ∏è Creating AST model with regression head...\")\n",
    "\n",
    "# Initialize regression model\n",
    "regression_model = ProductionASTForRegression(\n",
    "    patch_size=16,\n",
    "    embed_dim=768,\n",
    "    num_layers=12,\n",
    "    num_heads=12,\n",
    "    mlp_ratio=4.0,\n",
    "    dropout_rate=0.1,\n",
    "    attention_dropout=0.1,\n",
    "    stochastic_depth_rate=0.1,\n",
    "    num_outputs=19  # 19 perceptual dimensions\n",
    ")\n",
    "\n",
    "# Initialize model parameters\n",
    "dummy_input = jnp.ones((2, 128, 128))\n",
    "rng = jax.random.PRNGKey(42)\n",
    "init_rng, dropout_rng, stochastic_rng = jax.random.split(rng, 3)\n",
    "\n",
    "new_params = regression_model.init(\n",
    "    {'params': init_rng, 'dropout': dropout_rng, 'stochastic_depth': stochastic_rng},\n",
    "    dummy_input,\n",
    "    training=False\n",
    ")\n",
    "\n",
    "# Load pre-trained weights\n",
    "pretrained_checkpoint_path = '/content/drive/MyDrive/piano_transformer/checkpoints/ssast_pretraining/pretrained_for_finetuning.pkl'\n",
    "\n",
    "if os.path.exists(pretrained_checkpoint_path):\n",
    "    pretrained_params, pretrained_checkpoint = load_pretrained_weights(regression_model, pretrained_checkpoint_path)\n",
    "    \n",
    "    # Transfer pre-trained weights\n",
    "    final_params = transfer_pretrained_weights(pretrained_params, new_params)\n",
    "    \n",
    "    print(f\"‚úÖ Pre-trained weights loaded and transferred successfully!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Pre-trained checkpoint not found: {pretrained_checkpoint_path}\")\n",
    "    print(f\"   Using randomly initialized weights for all layers\")\n",
    "    final_params = new_params\n",
    "\n",
    "# Count parameters\n",
    "param_count = sum(x.size for x in jax.tree.leaves(final_params))\n",
    "print(f\"\\nüìä Regression Model Statistics:\")\n",
    "print(f\"   ‚Ä¢ Total parameters: {param_count:,}\")\n",
    "print(f\"   ‚Ä¢ Memory usage: ~{param_count * 4 / 1024**2:.1f} MB (FP32)\")\n",
    "print(f\"   ‚Ä¢ Architecture: 12-layer AST + regression head\")\n",
    "print(f\"   ‚Ä¢ Output dimensions: 19 perceptual features\")\n",
    "\n",
    "# Test forward pass\n",
    "print(f\"\\nüöÄ Testing regression model forward pass...\")\n",
    "output = regression_model.apply(\n",
    "    final_params, dummy_input,\n",
    "    training=False,\n",
    "    rngs={'dropout': dropout_rng, 'stochastic_depth': stochastic_rng}\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Forward pass successful!\")\n",
    "print(f\"   ‚Ä¢ Input shape: {dummy_input.shape}\")\n",
    "print(f\"   ‚Ä¢ Output shape: {output.shape}\")\n",
    "print(f\"   ‚Ä¢ Output stats: min={output.min():.4f}, max={output.max():.4f}, mean={output.mean():.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ Ready for supervised fine-tuning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Cell 4: Execute Supervised Fine-tuning\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('./src')\n",
    "\n",
    "print(\"üéØ SUPERVISED FINE-TUNING - EXECUTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check prerequisites\n",
    "if 'train_dataset' not in locals():\n",
    "    raise RuntimeError(\"Run Cell 2 first to load PercePiano dataset\")\n",
    "\n",
    "if 'regression_model' not in locals():\n",
    "    raise RuntimeError(\"Run Cell 3 first to create regression model\")\n",
    "\n",
    "print(\"‚úÖ All prerequisites ready\")\n",
    "print(f\"   ‚Ä¢ PercePiano datasets loaded: ‚úÖ\")\n",
    "print(f\"   ‚Ä¢ Pre-trained AST with regression head: ‚úÖ\")\n",
    "print(f\"   ‚Ä¢ Fine-tuning pipeline: ‚úÖ\")\n",
    "print(f\"   ‚Ä¢ WandB experiment tracking: ‚úÖ\")\n",
    "\n",
    "def execute_supervised_finetuning(\n",
    "    model, params, train_dataset, val_dataset,\n",
    "    num_epochs=30, batch_size=16, patience=10\n",
    "):\n",
    "    \"\"\"Execute supervised fine-tuning on PercePiano dataset\"\"\"\n",
    "    print(\"üéØ Starting Supervised Fine-tuning...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Initialize random state\n",
    "    rng = jax.random.PRNGKey(42)\n",
    "    \n",
    "    # Training configuration\n",
    "    train_size = len(train_dataset)\n",
    "    steps_per_epoch = max(train_size // batch_size, 5)\n",
    "    total_steps = num_epochs * steps_per_epoch\n",
    "    \n",
    "    print(f\"üìä Fine-tuning Configuration:\")\n",
    "    print(f\"   ‚Ä¢ Model: {model.__class__.__name__}\")\n",
    "    print(f\"   ‚Ä¢ Parameters: {sum(x.size for x in jax.tree.leaves(params)):,}\")\n",
    "    print(f\"   ‚Ä¢ Train size: {train_size} samples\")\n",
    "    print(f\"   ‚Ä¢ Val size: {len(val_dataset)} samples\")\n",
    "    print(f\"   ‚Ä¢ Batch size: {batch_size}\")\n",
    "    print(f\"   ‚Ä¢ Steps per epoch: {steps_per_epoch}\")\n",
    "    print(f\"   ‚Ä¢ Total steps: {total_steps:,}\")\n",
    "    print(f\"   ‚Ä¢ Epochs: {num_epochs}\")\n",
    "    print(f\"   ‚Ä¢ Early stopping patience: {patience}\")\n",
    "    \n",
    "    # Create fine-tuning optimizer with lower learning rate\n",
    "    optimizer = create_finetuning_optimizer(\n",
    "        total_steps=total_steps,\n",
    "        learning_rate=1e-4,  # Lower than pre-training\n",
    "        weight_decay=0.01,\n",
    "        warmup_steps=total_steps // 10\n",
    "    )\n",
    "    \n",
    "    # Create training state\n",
    "    train_state_obj = train_state.TrainState.create(\n",
    "        apply_fn=model.apply,\n",
    "        params=params,\n",
    "        tx=optimizer\n",
    "    )\n",
    "    \n",
    "    # Training tracking\n",
    "    best_val_correlation = -1.0  # Best correlation (higher is better)\n",
    "    patience_counter = 0\n",
    "    training_history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_correlation': [],\n",
    "        'val_correlation': [],\n",
    "        'learning_rates': []\n",
    "    }\n",
    "    \n",
    "    # Create checkpoint directory\n",
    "    checkpoint_dir = '/content/drive/MyDrive/piano_transformer/checkpoints/finetuning'\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\nüéØ Starting fine-tuning loop...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # === TRAINING PHASE ===\n",
    "        train_metrics = []\n",
    "        \n",
    "        for step in range(steps_per_epoch):\n",
    "            # Get training batch\n",
    "            batch_specs, batch_labels = train_dataset.get_batch(batch_size, shuffle=True)\n",
    "            batch_specs = jnp.array(batch_specs)\n",
    "            batch_labels = jnp.array(batch_labels)\n",
    "            \n",
    "            # Generate RNG keys for this step\n",
    "            rng, dropout_rng, stochastic_rng = jax.random.split(rng, 3)\n",
    "            \n",
    "            # Training step\n",
    "            train_state_obj, metrics = finetuning_train_step(\n",
    "                train_state_obj, batch_specs, batch_labels, dropout_rng, stochastic_rng\n",
    "            )\n",
    "            \n",
    "            train_metrics.append(metrics)\n",
    "            \n",
    "            # Log to WandB every 5 steps\n",
    "            if step % 5 == 0:\n",
    "                try:\n",
    "                    wandb.log({\n",
    "                        \"train/total_loss\": float(metrics['total_loss']),\n",
    "                        \"train/mse_loss\": float(metrics['mse_loss']),\n",
    "                        \"train/correlation\": float(metrics['correlation']),\n",
    "                        \"train/prediction_mean\": float(metrics['prediction_mean']),\n",
    "                        \"train/prediction_std\": float(metrics['prediction_std']),\n",
    "                        \"train/grad_norm\": float(metrics['grad_norm']),\n",
    "                        \"train/learning_rate\": float(metrics['learning_rate']),\n",
    "                        \"epoch\": epoch,\n",
    "                        \"step\": int(train_state_obj.step)\n",
    "                    })\n",
    "                except:\n",
    "                    pass  # Continue if WandB fails\n",
    "        \n",
    "        # === VALIDATION PHASE ===\n",
    "        val_metrics = []\n",
    "        val_steps = max(len(val_dataset) // batch_size, 1)\n",
    "        \n",
    "        for val_step in range(val_steps):\n",
    "            batch_specs, batch_labels = val_dataset.get_batch(batch_size, shuffle=False)\n",
    "            batch_specs = jnp.array(batch_specs)\n",
    "            batch_labels = jnp.array(batch_labels)\n",
    "            \n",
    "            # Validation forward pass (no training)\n",
    "            rng, dropout_rng, stochastic_rng = jax.random.split(rng, 3)\n",
    "            \n",
    "            predictions = model.apply(\n",
    "                train_state_obj.params, batch_specs,\n",
    "                training=False,\n",
    "                rngs={'dropout': dropout_rng, 'stochastic_depth': stochastic_rng}\n",
    "            )\n",
    "            \n",
    "            # Compute validation metrics\n",
    "            val_mse = jnp.mean(jnp.square(predictions - batch_labels))\n",
    "            val_correlation = compute_correlation(predictions, batch_labels)\n",
    "            val_loss = val_mse - 0.1 * val_correlation  # Same as training loss\n",
    "            \n",
    "            val_metrics.append({\n",
    "                'val_loss': val_loss,\n",
    "                'val_mse': val_mse,\n",
    "                'val_correlation': val_correlation\n",
    "            })\n",
    "        \n",
    "        # === EPOCH SUMMARY ===\n",
    "        # Average metrics\n",
    "        avg_train_loss = np.mean([m['total_loss'] for m in train_metrics])\n",
    "        avg_train_correlation = np.mean([m['correlation'] for m in train_metrics])\n",
    "        avg_val_loss = np.mean([m['val_loss'] for m in val_metrics])\n",
    "        avg_val_correlation = np.mean([m['val_correlation'] for m in val_metrics])\n",
    "        avg_lr = np.mean([m['learning_rate'] for m in train_metrics])\n",
    "        \n",
    "        # Store history\n",
    "        training_history['train_loss'].append(avg_train_loss)\n",
    "        training_history['val_loss'].append(avg_val_loss)\n",
    "        training_history['train_correlation'].append(avg_train_correlation)\n",
    "        training_history['val_correlation'].append(avg_val_correlation)\n",
    "        training_history['learning_rates'].append(avg_lr)\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:3d}: \"\n",
    "              f\"Train Corr={avg_train_correlation:.4f}, \"\n",
    "              f\"Val Corr={avg_val_correlation:.4f}, \"\n",
    "              f\"Val Loss={avg_val_loss:.4f}, \"\n",
    "              f\"LR={avg_lr:.6f}, \"\n",
    "              f\"Time={epoch_time:.1f}s\")\n",
    "        \n",
    "        # Log epoch metrics to WandB\n",
    "        try:\n",
    "            wandb.log({\n",
    "                \"epoch/train_loss\": avg_train_loss,\n",
    "                \"epoch/val_loss\": avg_val_loss,\n",
    "                \"epoch/train_correlation\": avg_train_correlation,\n",
    "                \"epoch/val_correlation\": avg_val_correlation,\n",
    "                \"epoch/learning_rate\": avg_lr,\n",
    "                \"epoch/time_seconds\": epoch_time,\n",
    "                \"epoch/total_time_hours\": total_time / 3600,\n",
    "                \"epoch/epoch\": epoch + 1\n",
    "            })\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # === EARLY STOPPING & CHECKPOINTING ===\n",
    "        improved = avg_val_correlation > best_val_correlation\n",
    "        \n",
    "        if improved:\n",
    "            best_val_correlation = avg_val_correlation\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # Save best model\n",
    "            best_checkpoint = {\n",
    "                'params': train_state_obj.params,\n",
    "                'step': train_state_obj.step,\n",
    "                'epoch': epoch + 1,\n",
    "                'best_val_correlation': best_val_correlation,\n",
    "                'val_loss': avg_val_loss,\n",
    "                'training_history': training_history,\n",
    "                'model_config': {\n",
    "                    'embed_dim': 768,\n",
    "                    'num_layers': 12,\n",
    "                    'num_heads': 12,\n",
    "                    'patch_size': 16,\n",
    "                    'num_outputs': 19\n",
    "                },\n",
    "                'label_scaler': train_dataset.label_scaler  # Include scaler for inference\n",
    "            }\n",
    "            \n",
    "            best_path = os.path.join(checkpoint_dir, 'best_finetuned_model.pkl')\n",
    "            with open(best_path, 'wb') as f:\n",
    "                pickle.dump(best_checkpoint, f)\n",
    "            \n",
    "            print(f\"   ‚úÖ New best model saved (val_correlation: {best_val_correlation:.4f})\")\n",
    "            \n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"   ‚è≥ No improvement ({patience_counter}/{patience})\")\n",
    "        \n",
    "        # Regular checkpoint every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pkl')\n",
    "            regular_checkpoint = {\n",
    "                'params': train_state_obj.params,\n",
    "                'step': train_state_obj.step,\n",
    "                'epoch': epoch + 1,\n",
    "                'val_correlation': avg_val_correlation,\n",
    "                'val_loss': avg_val_loss,\n",
    "                'training_history': training_history,\n",
    "                'label_scaler': train_dataset.label_scaler\n",
    "            }\n",
    "            with open(checkpoint_path, 'wb') as f:\n",
    "                pickle.dump(regular_checkpoint, f)\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nüõë Early stopping after {patience} epochs without improvement\")\n",
    "            print(f\"   Best validation correlation: {best_val_correlation:.4f}\")\n",
    "            break\n",
    "    \n",
    "    # === FINE-TUNING COMPLETE ===\n",
    "    total_training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"üéâ SUPERVISED FINE-TUNING COMPLETED!\")\n",
    "    print(f\"=\"*60)\n",
    "    print(f\"üìà Final Results:\")\n",
    "    print(f\"   ‚Ä¢ Best validation correlation: {best_val_correlation:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Final validation loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Total epochs: {epoch + 1}\")\n",
    "    print(f\"   ‚Ä¢ Total steps: {train_state_obj.step:,}\")\n",
    "    print(f\"   ‚Ä¢ Training time: {total_training_time/60:.1f} minutes\")\n",
    "    print(f\"   ‚Ä¢ Final learning rate: {avg_lr:.2e}\")\n",
    "    \n",
    "    return train_state_obj, best_val_correlation, training_history\n",
    "\n",
    "# Execute supervised fine-tuning\n",
    "try:\n",
    "    print(f\"\\nüéØ Starting Supervised Fine-tuning on PercePiano dataset...\")\n",
    "    print(f\"   ‚Ä¢ Using pre-trained AST with regression head\")\n",
    "    print(f\"   ‚Ä¢ Training set: {len(train_dataset)} samples (MIDI‚Üíspectrogram)\")\n",
    "    print(f\"   ‚Ä¢ Validation set: {len(val_dataset)} samples\")\n",
    "    print(f\"   ‚Ä¢ Target: 19 perceptual dimensions\")\n",
    "    print(f\"   ‚Ä¢ Lower learning rate for stable fine-tuning\")\n",
    "    print(f\"   ‚Ä¢ Early stopping with patience=10\")\n",
    "    print(f\"   ‚Ä¢ Correlation-based evaluation\")\n",
    "    \n",
    "    # Execute fine-tuning\n",
    "    final_state, best_correlation, history = execute_supervised_finetuning(\n",
    "        model=regression_model,\n",
    "        params=final_params,\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        num_epochs=30,   # Sufficient for fine-tuning\n",
    "        batch_size=16,   # Smaller batch size for fine-tuning\n",
    "        patience=10      # Early stopping patience\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüéâ SUPERVISED FINE-TUNING COMPLETED SUCCESSFULLY!\")\n",
    "    print(f\"=\"*70)\n",
    "    \n",
    "    # Save final fine-tuned model for evaluation\n",
    "    finetuned_model_path = '/content/drive/MyDrive/piano_transformer/checkpoints/finetuning/final_finetuned_model.pkl'\n",
    "    final_checkpoint = {\n",
    "        'params': final_state.params,\n",
    "        'model_config': {\n",
    "            'embed_dim': 768,\n",
    "            'num_layers': 12,\n",
    "            'num_heads': 12,\n",
    "            'patch_size': 16,\n",
    "            'num_outputs': 19\n",
    "        },\n",
    "        'finetuning_results': {\n",
    "            'best_val_correlation': float(best_correlation),\n",
    "            'total_epochs': len(history['train_loss']),\n",
    "            'convergence_achieved': best_correlation > 0.5  # Good correlation threshold\n",
    "        },\n",
    "        'label_scaler': train_dataset.label_scaler,\n",
    "        'training_complete': True\n",
    "    }\n",
    "    \n",
    "    with open(finetuned_model_path, 'wb') as f:\n",
    "        pickle.dump(final_checkpoint, f)\n",
    "    \n",
    "    print(f\"üíæ Fine-tuned model saved for evaluation: {finetuned_model_path}\")\n",
    "    print(f\"üéØ READY FOR COMPREHENSIVE EVALUATION!\")\n",
    "    \n",
    "    # Performance summary\n",
    "    if best_correlation > 0.7:\n",
    "        print(f\"üéâ Excellent correlation achieved: {best_correlation:.4f} > 0.70\")\n",
    "    elif best_correlation > 0.5:\n",
    "        print(f\"‚úÖ Good correlation achieved: {best_correlation:.4f} > 0.50\")\n",
    "    elif best_correlation > 0.3:\n",
    "        print(f\"‚ö†Ô∏è Moderate correlation: {best_correlation:.4f} > 0.30\")\n",
    "    else:\n",
    "        print(f\"‚ùå Low correlation: {best_correlation:.4f} < 0.30 - May need more training\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Supervised fine-tuning failed: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Fine-tuning Complete!\n",
    "\n",
    "**Next Steps:**\n",
    "1. üìä **Evaluation**: Run `3_Piano_Transformer_Evaluation.ipynb` for comprehensive performance analysis\n",
    "2. üîç **Analysis**: Examine per-dimension correlations and model interpretability\n",
    "3. üìà **Comparison**: Compare with baseline models and human performance\n",
    "\n",
    "**Fine-tuned Model Location:**\n",
    "```\n",
    "/content/drive/MyDrive/piano_transformer/checkpoints/finetuning/final_finetuned_model.pkl\n",
    "```\n",
    "\n",
    "**Model Configuration:**\n",
    "- **Architecture**: Pre-trained 12-layer AST + regression head\n",
    "- **Input**: 128√ó128 mel-spectrograms from MIDI synthesis\n",
    "- **Output**: 19 normalized perceptual dimensions\n",
    "- **Training**: Supervised learning with correlation-based loss\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}